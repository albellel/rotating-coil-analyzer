{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01-title",
   "metadata": {},
   "source": [
    "# Golden Standard Parity Validation v2 -- LIU BTP8 Integral Coil\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Validate that the Python analysis pipeline (`kn_pipeline.py`) produces **identical results**\n",
    "to the legacy C++ analyzer (ffmm / MATLAB Coder path) on the LIU BTP8 integral coil dataset.\n",
    "\n",
    "## Key improvements over v1\n",
    "\n",
    "- **Sequential turn selection**: takes the first `TURNS_PER_RUN` turns from each run,\n",
    "  matching the C++ `Parameters.Measurement.turns` behavior exactly.\n",
    "  Greedy B2 matching is used only as verification, not as the primary alignment strategy.\n",
    "- **Current-threshold filtering**: parity tables at |I| >= 0, 10, 50, 100 A.\n",
    "- **Error distribution analysis**: histograms, per-harmonic RMS, worst-turn diagnostics.\n",
    "\n",
    "## Key findings\n",
    "\n",
    "| Metric | Result |\n",
    "|--------|--------|\n",
    "| B2 (main field) | Sub-ppm match (< 1e-6 relative) |\n",
    "| b3 at \\|I\\| >= 50 A | 97.6% of turns within 0.001 units |\n",
    "| All harmonics at \\|I\\| >= 100 A | EXCELLENT or GOOD for n <= 6 |\n",
    "| Root cause of residuals | Turn selection ambiguity in low-current runs |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET CONFIGURATION\n",
    "# =============================================================================\n",
    "DATASET = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/Integral/20190717_161332_LIU\")\n",
    "KN_PATH = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/COIL_PCB/Kn_R45_PCB_N1_0001_A_ABCD.txt\")\n",
    "\n",
    "# Magnet parameters (from BTP8_20190717_161332_Parameters.txt)\n",
    "MAGNET_ORDER = 2           # Quadrupole\n",
    "R_REF_M = 0.059            # Reference radius [m]\n",
    "SAMPLES_PER_TURN = 512     # BTP8 encoder resolution\n",
    "SHAFT_SPEED_RPM = 60       # Rotation speed (absolute value)\n",
    "\n",
    "# Pipeline options: run WITHOUT \"nor\" -- normalise post-merge to match\n",
    "# the reference mixed format (Tesla for n<=m, units for n>m).\n",
    "OPTIONS = (\"dri\", \"rot\", \"cel\", \"fed\")\n",
    "\n",
    "# Number of measurement turns the legacy software keeps per run.\n",
    "# Flux files contain ~14 turns, but only the first 6 are saved to results.\n",
    "TURNS_PER_RUN = 6\n",
    "\n",
    "print(\"Configuration\")\n",
    "print(f\"  Dataset       : {DATASET}\")\n",
    "print(f\"  Kn file       : {KN_PATH.name}\")\n",
    "print(f\"  Magnet order  : {MAGNET_ORDER} (quadrupole)\")\n",
    "print(f\"  R_ref         : {R_REF_M} m\")\n",
    "print(f\"  Samples/turn  : {SAMPLES_PER_TURN}\")\n",
    "print(f\"  Options       : {OPTIONS}\")\n",
    "print(f\"  Turns per run : {TURNS_PER_RUN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add repo root to path\n",
    "repo_root = Path(\"../..\").resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from rotating_coil_analyzer.analysis.kn_pipeline import (\n",
    "    load_segment_kn_txt,\n",
    "    compute_legacy_kn_per_turn,\n",
    "    merge_coefficients,\n",
    ")\n",
    "\n",
    "# Resolve paths\n",
    "notebook_dir = Path(\".\").resolve()\n",
    "dataset_folder = (notebook_dir / DATASET).resolve()\n",
    "kn_file = (notebook_dir / KN_PATH).resolve()\n",
    "\n",
    "assert dataset_folder.exists(), f\"Dataset not found: {dataset_folder}\"\n",
    "assert kn_file.exists(), f\"Kn file not found: {kn_file}\"\n",
    "print(f\"Dataset : {dataset_folder}\")\n",
    "print(f\"Kn file : {kn_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-ref-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Reference Data\n",
    "\n",
    "The golden reference was produced by the **MATLAB Coder path** of the legacy\n",
    "analyzer with options `\"dri rot nor cel fed\"`.  The output format is mixed:\n",
    "\n",
    "- `B1 (T)`, `B2 (T)` -- Tesla (absolute field, post-rotation)\n",
    "- `b3 (units)` ... `b15 (units)` -- normalised (`C_n / C_m * 10000`)\n",
    "- `Angle (rad)` -- rotation angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05-load-ref",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load the reference results file\n",
    "ref_files = [\n",
    "    f for f in dataset_folder.glob(\"*results*.txt\")\n",
    "    if \"Average\" not in f.name and \"Parameters\" not in f.name\n",
    "]\n",
    "assert ref_files, \"No reference results file found\"\n",
    "ref_path = ref_files[0]\n",
    "\n",
    "ref_df = pd.read_csv(ref_path, sep=\"\\t\")\n",
    "print(f\"Reference: {ref_path.name}\")\n",
    "print(f\"  Shape          : {ref_df.shape}\")\n",
    "print(f\"  Turns          : {len(ref_df)}\")\n",
    "\n",
    "# Identify current and main-field columns\n",
    "I_col = next((c for c in ref_df.columns if \"I(A)\" in c or \"I FGC\" in c), None)\n",
    "main_col = next((c for c in ref_df.columns if f\"B{MAGNET_ORDER}\" in c and \"T\" in c), None)\n",
    "\n",
    "if I_col:\n",
    "    I_ref = ref_df[I_col].values.astype(float)\n",
    "    print(f\"  Current range  : [{I_ref.min():.1f}, {I_ref.max():.1f}] A\")\n",
    "if main_col:\n",
    "    print(f\"  {main_col} range: [{ref_df[main_col].min():.6e}, {ref_df[main_col].max():.6e}] T\")\n",
    "\n",
    "print(f\"  Options        : {ref_df['Options'].iloc[0].strip() if 'Options' in ref_df.columns else 'N/A'}\")\n",
    "print(f\"\\nFirst 3 rows (selected columns):\")\n",
    "show_cols = [c for c in ref_df.columns if any(k in c for k in [\"I(A)\", \"B1\", \"B2\", \"b3\", \"Angle\"])][:6]\n",
    "display(ref_df[show_cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-06-raw-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Raw Data & Kn\n",
    "\n",
    "BTP8 flux files have 4 columns: `df_abs | encoder | df_cmp | encoder`.\n",
    "Current files are single-column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07-load-raw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Load Kn calibration --\n",
    "kn = load_segment_kn_txt(kn_file)\n",
    "print(f\"Kn: {len(kn.orders)} harmonics from {kn_file.name}\")\n",
    "\n",
    "# -- BTP8 parsers --\n",
    "def parse_btp8_flux(path):\n",
    "    data = np.loadtxt(path)\n",
    "    return data[:, 0], data[:, 2], data[:, 1]   # df_abs, df_cmp, encoder\n",
    "\n",
    "def parse_btp8_current(path):\n",
    "    return np.loadtxt(path)\n",
    "\n",
    "def encoder_to_time(enc, rpm=SHAFT_SPEED_RPM, res=40000):\n",
    "    return enc / (rpm * res / 60.0)\n",
    "\n",
    "# -- Discover flux/current file pairs --\n",
    "flux_files = sorted(dataset_folder.glob(\"*_fluxes_Ascii.txt\"))\n",
    "current_files = sorted(dataset_folder.glob(\"*_current.txt\"))\n",
    "assert len(flux_files) == len(current_files), \"Flux/current file count mismatch\"\n",
    "n_runs = len(flux_files)\n",
    "\n",
    "print(f\"\\nDiscovered {n_runs} runs\")\n",
    "print(f\"Expected reference turns: {n_runs} x {TURNS_PER_RUN} = {n_runs * TURNS_PER_RUN}\")\n",
    "print(f\"Actual reference turns  : {len(ref_df)}\")\n",
    "\n",
    "# Quick sanity check on first file\n",
    "df_abs_0, df_cmp_0, enc_0 = parse_btp8_flux(flux_files[0])\n",
    "print(f\"\\nFirst file: {flux_files[0].name}\")\n",
    "print(f\"  Samples       : {len(df_abs_0)}\")\n",
    "print(f\"  Complete turns: {len(df_abs_0) // SAMPLES_PER_TURN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-pipeline-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Pipeline\n",
    "\n",
    "Process every run through `compute_legacy_kn_per_turn` + `merge_coefficients`.\n",
    "Store per-turn results with run and turn-in-run metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-09-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run(flux_path, current_path):\n",
    "    \"\"\"Process one BTP8 run through the full kn pipeline.\"\"\"\n",
    "    df_abs, df_cmp, encoder = parse_btp8_flux(flux_path)\n",
    "    current = parse_btp8_current(current_path)\n",
    "    time = encoder_to_time(encoder)\n",
    "\n",
    "    # Align current to flux length\n",
    "    n_flux = len(df_abs)\n",
    "    if len(current) != n_flux:\n",
    "        idx = np.linspace(0, len(current) - 1, n_flux).astype(int)\n",
    "        current = current[idx]\n",
    "\n",
    "    # Truncate to complete turns\n",
    "    n_turns = n_flux // SAMPLES_PER_TURN\n",
    "    n_samp = n_turns * SAMPLES_PER_TURN\n",
    "    shape = (n_turns, SAMPLES_PER_TURN)\n",
    "\n",
    "    result = compute_legacy_kn_per_turn(\n",
    "        df_abs_turns=df_abs[:n_samp].reshape(shape),\n",
    "        df_cmp_turns=df_cmp[:n_samp].reshape(shape),\n",
    "        t_turns=time[:n_samp].reshape(shape),\n",
    "        I_turns=current[:n_samp].reshape(shape),\n",
    "        kn=kn,\n",
    "        Rref_m=R_REF_M,\n",
    "        magnet_order=MAGNET_ORDER,\n",
    "        options=OPTIONS,\n",
    "    )\n",
    "    return result, n_turns\n",
    "\n",
    "\n",
    "# Process all runs, store per-turn rows with metadata\n",
    "rows = []\n",
    "for run_id, (fp, cp) in enumerate(zip(flux_files, current_files)):\n",
    "    result, n_turns = process_run(fp, cp)\n",
    "\n",
    "    C_merged, _ = merge_coefficients(\n",
    "        C_abs=result.C_abs, C_cmp=result.C_cmp,\n",
    "        magnet_order=MAGNET_ORDER, mode=\"abs_upto_m_cmp_above\",\n",
    "    )\n",
    "\n",
    "    for t in range(n_turns):\n",
    "        Bm = C_merged[t, MAGNET_ORDER - 1].real\n",
    "        row = {\n",
    "            \"run_id\": run_id,\n",
    "            \"turn_in_run\": t,\n",
    "            \"I_mean_A\": result.I_mean_A[t],\n",
    "        }\n",
    "        for i, n in enumerate(result.orders):\n",
    "            C = C_merged[t, i]\n",
    "            if n <= MAGNET_ORDER:\n",
    "                row[f\"B{n}_T\"] = C.real\n",
    "                row[f\"A{n}_T\"] = C.imag\n",
    "            else:\n",
    "                if abs(Bm) > 1e-30:\n",
    "                    row[f\"b{n}_units\"] = C.real / Bm * 10000.0\n",
    "                    row[f\"a{n}_units\"] = C.imag / Bm * 10000.0\n",
    "                else:\n",
    "                    row[f\"b{n}_units\"] = np.nan\n",
    "                    row[f\"a{n}_units\"] = np.nan\n",
    "        rows.append(row)\n",
    "\n",
    "computed_df = pd.DataFrame(rows)\n",
    "print(f\"Processed {n_runs} runs -> {len(computed_df)} total turns\")\n",
    "print(f\"  Turns per run: {computed_df.groupby('run_id').size().unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10-alignment-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Turn Selection & Alignment\n",
    "\n",
    "The legacy software keeps the **first `TURNS_PER_RUN` turns** from each run\n",
    "(set by `Parameters.Measurement.turns`). The flux files contain ~14 turns,\n",
    "but only turns 0..5 correspond to the reference rows.\n",
    "\n",
    "**Strategy**: For each run (in order), take turns 0..`TURNS_PER_RUN-1`.\n",
    "Verify alignment by checking that B2 matches the corresponding reference row\n",
    "within sub-ppm tolerance. If verification fails, fall back to greedy B2 search\n",
    "within that run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Sequential alignment: first TURNS_PER_RUN turns from each run --\n",
    "ref_b2 = ref_df[main_col].values.astype(float)\n",
    "\n",
    "aligned_indices = []\n",
    "alignment_log = []\n",
    "ref_row = 0\n",
    "\n",
    "for run_id in range(n_runs):\n",
    "    run_mask = computed_df[\"run_id\"] == run_id\n",
    "    run_df = computed_df[run_mask]\n",
    "    run_global_indices = run_df.index.tolist()\n",
    "\n",
    "    # Take the first TURNS_PER_RUN turns from this run\n",
    "    selected = run_global_indices[:TURNS_PER_RUN]\n",
    "\n",
    "    for local_t, gi in enumerate(selected):\n",
    "        if ref_row >= len(ref_b2):\n",
    "            break\n",
    "        comp_b2 = computed_df.loc[gi, \"B2_T\"]\n",
    "        ref_val = ref_b2[ref_row]\n",
    "        diff = abs(comp_b2 - ref_val)\n",
    "        rel = diff / max(abs(ref_val), 1e-30)\n",
    "\n",
    "        status = \"OK\" if rel < 1e-4 else \"FALLBACK\"\n",
    "        if status == \"OK\":\n",
    "            aligned_indices.append(gi)\n",
    "        else:\n",
    "            # Fallback: greedy search within this run\n",
    "            best_gi, best_rel = gi, rel\n",
    "            for cand_gi in run_global_indices:\n",
    "                if cand_gi in aligned_indices:\n",
    "                    continue\n",
    "                cand_b2 = computed_df.loc[cand_gi, \"B2_T\"]\n",
    "                cand_rel = abs(cand_b2 - ref_val) / max(abs(ref_val), 1e-30)\n",
    "                if cand_rel < best_rel:\n",
    "                    best_rel = cand_rel\n",
    "                    best_gi = cand_gi\n",
    "            aligned_indices.append(best_gi)\n",
    "            status = f\"FALLBACK(rel={best_rel:.2e})\"\n",
    "\n",
    "        alignment_log.append({\n",
    "            \"ref_row\": ref_row,\n",
    "            \"run_id\": run_id,\n",
    "            \"turn_in_run\": computed_df.loc[aligned_indices[-1], \"turn_in_run\"],\n",
    "            \"B2_ref\": ref_val,\n",
    "            \"B2_comp\": computed_df.loc[aligned_indices[-1], \"B2_T\"],\n",
    "            \"rel_diff\": abs(computed_df.loc[aligned_indices[-1], \"B2_T\"] - ref_val) / max(abs(ref_val), 1e-30),\n",
    "            \"status\": status,\n",
    "        })\n",
    "        ref_row += 1\n",
    "\n",
    "aligned_df = computed_df.iloc[aligned_indices].reset_index(drop=True)\n",
    "align_log_df = pd.DataFrame(alignment_log)\n",
    "\n",
    "# Diagnostics\n",
    "n_ok = (align_log_df[\"status\"] == \"OK\").sum()\n",
    "n_fallback = len(align_log_df) - n_ok\n",
    "max_rel = align_log_df[\"rel_diff\"].max()\n",
    "\n",
    "print(f\"Aligned {len(aligned_df)} / {len(ref_df)} reference turns\")\n",
    "print(f\"  Sequential OK : {n_ok}\")\n",
    "print(f\"  Fallback      : {n_fallback}\")\n",
    "print(f\"  Max B2 rel err: {max_rel:.2e}\")\n",
    "\n",
    "if n_fallback > 0:\n",
    "    print(\"\\nFallback turns:\")\n",
    "    display(align_log_df[align_log_df[\"status\"] != \"OK\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-parity-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Parity Results\n",
    "\n",
    "Compare computed harmonics against reference at multiple current thresholds.\n",
    "\n",
    "**Status thresholds** (on max relative difference):\n",
    "\n",
    "| Status | Max |rel diff| |\n",
    "|--------|----------------|\n",
    "| EXCELLENT | < 1e-6 |\n",
    "| GOOD | < 1e-3 |\n",
    "| CLOSE | < 0.1 |\n",
    "| MARGINAL | < 1.0 |\n",
    "| MISMATCH | >= 1.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-parity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_ref_col(n, component=\"B\"):\n",
    "    \"\"\"Find reference column for harmonic n.\"\"\"\n",
    "    for pat in [\n",
    "        f\"{component}{n} (T)\", f\"{component}{n}(T)\",\n",
    "        f\"{component.lower()}{n} (units)\", f\"{component.lower()}{n}(units)\",\n",
    "        f\"{component}{n} (units)\", f\"{component}{n}(units)\",\n",
    "        f\"{component}{n}\",\n",
    "    ]:\n",
    "        if pat in ref_df.columns:\n",
    "            return pat\n",
    "    return None\n",
    "\n",
    "\n",
    "def classify(max_rel):\n",
    "    if max_rel < 1e-6:   return \"EXCELLENT\"\n",
    "    if max_rel < 1e-3:   return \"GOOD\"\n",
    "    if max_rel < 0.1:    return \"CLOSE\"\n",
    "    if max_rel < 1.0:    return \"MARGINAL\"\n",
    "    return \"MISMATCH\"\n",
    "\n",
    "\n",
    "def parity_table(mask, label):\n",
    "    \"\"\"Compute parity for turns selected by mask.\"\"\"\n",
    "    n_sel = mask.sum()\n",
    "    results = []\n",
    "    for n in range(1, 16):\n",
    "        ref_col = _find_ref_col(n, \"B\")\n",
    "        if ref_col is None:\n",
    "            continue\n",
    "        comp_col = f\"B{n}_T\" if n <= MAGNET_ORDER else f\"b{n}_units\"\n",
    "        if comp_col not in aligned_df.columns:\n",
    "            continue\n",
    "\n",
    "        cv = aligned_df.loc[mask, comp_col].values\n",
    "        rv = ref_df.loc[mask, ref_col].values.astype(float)\n",
    "\n",
    "        ad = np.abs(cv - rv)\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            rd = np.where(np.abs(rv) > 1e-30, np.abs((cv - rv) / rv), 0.0)\n",
    "\n",
    "        results.append({\n",
    "            \"n\": n,\n",
    "            \"ref_col\": ref_col,\n",
    "            \"comp_col\": comp_col,\n",
    "            \"max_abs\": np.max(ad),\n",
    "            \"max_rel\": float(np.nanmax(rd)),\n",
    "            \"rms\": np.sqrt(np.mean(ad**2)),\n",
    "            \"status\": classify(float(np.nanmax(rd))),\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Get current values for filtering\n",
    "I_aligned = aligned_df[\"I_mean_A\"].values\n",
    "I_ref_aligned = ref_df[I_col].values.astype(float) if I_col else I_aligned\n",
    "\n",
    "# Parity tables at different current thresholds\n",
    "thresholds = [(\"All turns\", np.ones(len(aligned_df), dtype=bool)),\n",
    "              (\"|I| >= 10 A\", np.abs(I_ref_aligned) >= 10),\n",
    "              (\"|I| >= 50 A\", np.abs(I_ref_aligned) >= 50),\n",
    "              (\"|I| >= 100 A\", np.abs(I_ref_aligned) >= 100)]\n",
    "\n",
    "for label, mask in thresholds:\n",
    "    tbl = parity_table(mask, label)\n",
    "    n_sel = mask.sum()\n",
    "    print(f\"\\n{'=' * 100}\")\n",
    "    print(f\"  {label}  ({n_sel} turns)\")\n",
    "    print(f\"{'=' * 100}\")\n",
    "    print(f\"{'n':>3} {'ref_col':>20} {'comp_col':>16} {'max|diff|':>14} {'max|rel|':>14} {'RMS':>14} {'status':>12}\")\n",
    "    print(\"-\" * 100)\n",
    "    for _, r in tbl.iterrows():\n",
    "        print(f\"{r['n']:3.0f} {r['ref_col']:>20s} {r['comp_col']:>16s} \"\n",
    "              f\"{r['max_abs']:14.6e} {r['max_rel']:14.6e} {r['rms']:14.6e} {r['status']:>12s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14-error-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Error Analysis\n",
    "\n",
    "Detailed breakdown of where and why residual differences occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-error-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# --- (a) B2 time series ---\n",
    "ax = axes[0, 0]\n",
    "rv = ref_df[main_col].values[:len(aligned_df)].astype(float)\n",
    "cv = aligned_df[\"B2_T\"].values\n",
    "ax.plot(rv, \"b-\", label=\"Reference\", alpha=0.7)\n",
    "ax.plot(cv, \"r--\", label=\"Computed\", alpha=0.7)\n",
    "ax.set_xlabel(\"Turn\")\n",
    "ax.set_ylabel(main_col)\n",
    "ax.set_title(f\"Main Field (n={MAGNET_ORDER}): Time Series\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (b) b3 difference histogram (|I| >= 50 A) ---\n",
    "ax = axes[0, 1]\n",
    "b3_ref_col = _find_ref_col(3, \"B\") or _find_ref_col(3, \"b\")\n",
    "if b3_ref_col and \"b3_units\" in aligned_df.columns:\n",
    "    hi_mask = np.abs(I_ref_aligned) >= 50\n",
    "    if hi_mask.sum() > 0:\n",
    "        b3_diff = aligned_df.loc[hi_mask, \"b3_units\"].values - ref_df.loc[hi_mask, b3_ref_col].values.astype(float)\n",
    "        ax.hist(b3_diff, bins=40, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "        ax.axvline(0, color=\"r\", linestyle=\"--\")\n",
    "        within_001 = (np.abs(b3_diff) < 0.001).sum()\n",
    "        ax.set_title(f\"b3 diff (|I|>=50A): {within_001}/{len(b3_diff)} within 0.001\")\n",
    "    else:\n",
    "        ax.set_title(\"b3 diff: no turns at |I|>=50A\")\n",
    "else:\n",
    "    ax.set_title(\"b3 column not found\")\n",
    "ax.set_xlabel(\"b3 difference (units)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (c) Worst-turn analysis (B2) ---\n",
    "ax = axes[1, 0]\n",
    "b2_rel = np.abs(cv - rv) / np.maximum(np.abs(rv), 1e-30)\n",
    "ax.semilogy(b2_rel, \".\", markersize=4)\n",
    "ax.axhline(1e-6, color=\"g\", linestyle=\"--\", label=\"1 ppm\")\n",
    "ax.set_xlabel(\"Turn\")\n",
    "ax.set_ylabel(\"B2 relative difference\")\n",
    "ax.set_title(\"B2 per-turn relative error\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (d) Per-harmonic RMS error bar chart ---\n",
    "ax = axes[1, 1]\n",
    "all_tbl = parity_table(np.ones(len(aligned_df), dtype=bool), \"all\")\n",
    "ax.bar(all_tbl[\"n\"].values, all_tbl[\"rms\"].values, color=\"teal\", edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Harmonic order n\")\n",
    "ax.set_ylabel(\"RMS difference\")\n",
    "ax.set_title(\"Per-harmonic RMS error (all turns)\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total aligned turns : {len(aligned_df)} / {len(ref_df)}\")\n",
    "print(f\"B2 max rel error    : {b2_rel.max():.2e}\")\n",
    "if b3_ref_col and \"b3_units\" in aligned_df.columns:\n",
    "    b3_all_diff = aligned_df[\"b3_units\"].values - ref_df[b3_ref_col].values[:len(aligned_df)].astype(float)\n",
    "    print(f\"b3 RMS (all turns)  : {np.sqrt(np.mean(b3_all_diff**2)):.6f} units\")\n",
    "    if hi_mask.sum() > 0:\n",
    "        print(f\"b3 within 0.001     : {within_001}/{len(b3_diff)} at |I|>=50A\")\n",
    "\n",
    "# Status counts\n",
    "for label, mask in thresholds:\n",
    "    tbl = parity_table(mask, label)\n",
    "    counts = tbl[\"status\"].value_counts()\n",
    "    summary = \", \".join(f\"{s}: {counts.get(s, 0)}\" for s in [\"EXCELLENT\", \"GOOD\", \"CLOSE\", \"MARGINAL\", \"MISMATCH\"])\n",
    "    print(f\"\\n{label} ({mask.sum()} turns): {summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}