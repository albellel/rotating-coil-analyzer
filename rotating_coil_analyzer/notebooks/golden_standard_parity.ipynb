{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-01-title",
   "metadata": {},
   "source": [
    "# Golden Standard Parity Validation v2 -- LIU BTP8 Integral Coil\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Validate that the Python analysis pipeline (`kn_pipeline.py`) produces **identical results**\n",
    "to the legacy C++ analyzer (ffmm / MATLAB Coder path) on the LIU BTP8 integral coil dataset.\n",
    "\n",
    "## Key improvements over v1\n",
    "\n",
    "- **Sequential turn selection**: takes the first `TURNS_PER_RUN` turns from each run,\n",
    "  matching the C++ `Parameters.Measurement.turns` behavior exactly.\n",
    "  Greedy B2 matching is used only as verification, not as the primary alignment strategy.\n",
    "- **Current-threshold filtering**: parity tables at |I| >= 0, 10, 50, 100 A.\n",
    "- **Error distribution analysis**: histograms, per-harmonic RMS, worst-turn diagnostics.\n",
    "\n",
    "## Key findings\n",
    "\n",
    "| Metric | Result |\n",
    "|--------|--------|\n",
    "| B2 (main field) | Sub-ppm match (< 1e-6 relative) |\n",
    "| b3 at \\|I\\| >= 50 A | 97.6% of turns within 0.001 units |\n",
    "| All harmonics at \\|I\\| >= 100 A | EXCELLENT or GOOD for n <= 6 |\n",
    "| Root cause of residuals | Turn selection ambiguity in low-current runs |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02-config",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\n# =============================================================================\n# DATASET CONFIGURATION\n# =============================================================================\nDATASET = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/Integral/20190717_161332_LIU\")\nKN_PATH = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/COIL_PCB/Kn_R45_PCB_N1_0001_A_ABCD.txt\")\n\n# Magnet parameters (from BTP8_20190717_161332_Parameters.txt)\nMAGNET_ORDER = 2           # Quadrupole\nR_REF_M = 0.059            # Reference radius [m]\nSAMPLES_PER_TURN = 512     # BTP8 encoder resolution\nSHAFT_SPEED_RPM = 60       # Rotation speed (absolute value)\n\n# Pipeline options: run WITHOUT \"nor\" -- normalise post-merge to match\n# the reference mixed format (Tesla for n<=m, units for n>m).\nOPTIONS = (\"dri\", \"rot\", \"cel\", \"fed\")\n\nprint(\"Configuration\")\nprint(f\"  Dataset       : {DATASET}\")\nprint(f\"  Kn file       : {KN_PATH.name}\")\nprint(f\"  Magnet order  : {MAGNET_ORDER} (quadrupole)\")\nprint(f\"  R_ref         : {R_REF_M} m\")\nprint(f\"  Samples/turn  : {SAMPLES_PER_TURN}\")\nprint(f\"  Options       : {OPTIONS}\")"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-03-imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset : C:\\Users\\albellel\\python-projects\\rotating-coil-analyzer\\golden_standards\\golden_standard_01_LIU_BTP8\\Integral\\20190717_161332_LIU\n",
      "Kn file : C:\\Users\\albellel\\python-projects\\rotating-coil-analyzer\\golden_standards\\golden_standard_01_LIU_BTP8\\COIL_PCB\\Kn_R45_PCB_N1_0001_A_ABCD.txt\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add repo root to path\n",
    "repo_root = Path(\"../..\").resolve()\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "from rotating_coil_analyzer.analysis.kn_pipeline import (\n",
    "    load_segment_kn_txt,\n",
    "    compute_legacy_kn_per_turn,\n",
    "    merge_coefficients,\n",
    ")\n",
    "\n",
    "# Resolve paths\n",
    "notebook_dir = Path(\".\").resolve()\n",
    "dataset_folder = (notebook_dir / DATASET).resolve()\n",
    "kn_file = (notebook_dir / KN_PATH).resolve()\n",
    "\n",
    "assert dataset_folder.exists(), f\"Dataset not found: {dataset_folder}\"\n",
    "assert kn_file.exists(), f\"Kn file not found: {kn_file}\"\n",
    "print(f\"Dataset : {dataset_folder}\")\n",
    "print(f\"Kn file : {kn_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04-ref-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Reference Data\n",
    "\n",
    "The golden reference was produced by the **MATLAB Coder path** of the legacy\n",
    "analyzer with options `\"dri rot nor cel fed\"`.  The output format is mixed:\n",
    "\n",
    "- `B1 (T)`, `B2 (T)` -- Tesla (absolute field, post-rotation)\n",
    "- `b3 (units)` ... `b15 (units)` -- normalised (`C_n / C_m * 10000`)\n",
    "- `Angle (rad)` -- rotation angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-05-load-ref",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: BTP8_20190717_161332_results.txt\n",
      "  Shape          : (222, 41)\n",
      "  Turns          : 222\n",
      "  Current range  : [-200.0, 200.0] A\n",
      "  B2 (T) range: [-1.378426e-01, 1.378610e-01] T\n",
      "  Options        : dri rot nor cel fed\n",
      "\n",
      "First 3 rows (selected columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I(A)</th>\n",
       "      <th>B1 (T)</th>\n",
       "      <th>B2 (T)</th>\n",
       "      <th>Angle (rad)</th>\n",
       "      <th>b3 (units)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003869</td>\n",
       "      <td>-1.577978e-09</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>-44.50626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.004139</td>\n",
       "      <td>4.446962e-09</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.005519</td>\n",
       "      <td>-45.20210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004139</td>\n",
       "      <td>4.824142e-10</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>-53.26323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       I(A)        B1 (T)    B2 (T)  Angle (rad)  b3 (units)\n",
       "0  0.003869 -1.577978e-09 -0.000096     0.009668   -44.50626\n",
       "1 -0.004139  4.446962e-09 -0.000098    -0.005519   -45.20210\n",
       "2 -0.004139  4.824142e-10 -0.000098     0.013468   -53.26323"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find and load the reference results file\n",
    "ref_files = [\n",
    "    f for f in dataset_folder.glob(\"*results*.txt\")\n",
    "    if \"Average\" not in f.name and \"Parameters\" not in f.name\n",
    "]\n",
    "assert ref_files, \"No reference results file found\"\n",
    "ref_path = ref_files[0]\n",
    "\n",
    "ref_df = pd.read_csv(ref_path, sep=\"\\t\")\n",
    "print(f\"Reference: {ref_path.name}\")\n",
    "print(f\"  Shape          : {ref_df.shape}\")\n",
    "print(f\"  Turns          : {len(ref_df)}\")\n",
    "\n",
    "# Identify current and main-field columns\n",
    "I_col = next((c for c in ref_df.columns if \"I(A)\" in c or \"I FGC\" in c), None)\n",
    "main_col = next((c for c in ref_df.columns if f\"B{MAGNET_ORDER}\" in c and \"T\" in c), None)\n",
    "\n",
    "if I_col:\n",
    "    I_ref = ref_df[I_col].values.astype(float)\n",
    "    print(f\"  Current range  : [{I_ref.min():.1f}, {I_ref.max():.1f}] A\")\n",
    "if main_col:\n",
    "    print(f\"  {main_col} range: [{ref_df[main_col].min():.6e}, {ref_df[main_col].max():.6e}] T\")\n",
    "\n",
    "print(f\"  Options        : {ref_df['Options'].iloc[0].strip() if 'Options' in ref_df.columns else 'N/A'}\")\n",
    "print(f\"\\nFirst 3 rows (selected columns):\")\n",
    "show_cols = [c for c in ref_df.columns if any(k in c for k in [\"I(A)\", \"B1\", \"B2\", \"b3\", \"Angle\"])][:6]\n",
    "display(ref_df[show_cols].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-06-raw-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Raw Data & Kn\n",
    "\n",
    "BTP8 flux files have 4 columns: `df_abs | encoder | df_cmp | encoder`.\n",
    "Current files are single-column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07-load-raw",
   "metadata": {},
   "outputs": [],
   "source": "# -- Load Kn calibration --\nkn = load_segment_kn_txt(kn_file)\nprint(f\"Kn: {len(kn.orders)} harmonics from {kn_file.name}\")\n\n# -- BTP8 parsers --\ndef parse_btp8_flux(path):\n    data = np.loadtxt(path)\n    return data[:, 0], data[:, 2], data[:, 1]   # df_abs, df_cmp, encoder\n\ndef parse_btp8_current(path):\n    return np.loadtxt(path)\n\ndef encoder_to_time(enc, rpm=SHAFT_SPEED_RPM, res=40000):\n    return enc / (rpm * res / 60.0)\n\n# -- Discover flux/current file pairs --\n# Use *Run* to exclude stray files like BTP8_precycle_current.txt\nflux_files = sorted(dataset_folder.glob(\"*_fluxes_Ascii.txt\"))\ncurrent_files = sorted(dataset_folder.glob(\"*Run*_current.txt\"))\nassert len(flux_files) == len(current_files), (\n    f\"Flux/current file count mismatch: {len(flux_files)} flux vs {len(current_files)} current\"\n)\nn_runs = len(flux_files)\n\nprint(f\"\\nDiscovered {n_runs} runs\")\nprint(f\"Reference turns : {len(ref_df)}\")\n\n# Quick sanity check on first file\ndf_abs_0, df_cmp_0, enc_0 = parse_btp8_flux(flux_files[0])\nprint(f\"\\nFirst file: {flux_files[0].name}\")\nprint(f\"  Samples       : {len(df_abs_0)}\")\nprint(f\"  Complete turns: {len(df_abs_0) // SAMPLES_PER_TURN}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-08-pipeline-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Run Pipeline\n",
    "\n",
    "Process every run through `compute_legacy_kn_per_turn` + `merge_coefficients`.\n",
    "Store per-turn results with run and turn-in-run metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-09-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run(flux_path, current_path):\n",
    "    \"\"\"Process one BTP8 run through the full kn pipeline.\"\"\"\n",
    "    df_abs, df_cmp, encoder = parse_btp8_flux(flux_path)\n",
    "    current = parse_btp8_current(current_path)\n",
    "    time = encoder_to_time(encoder)\n",
    "\n",
    "    # Align current to flux length\n",
    "    n_flux = len(df_abs)\n",
    "    if len(current) != n_flux:\n",
    "        idx = np.linspace(0, len(current) - 1, n_flux).astype(int)\n",
    "        current = current[idx]\n",
    "\n",
    "    # Truncate to complete turns\n",
    "    n_turns = n_flux // SAMPLES_PER_TURN\n",
    "    n_samp = n_turns * SAMPLES_PER_TURN\n",
    "    shape = (n_turns, SAMPLES_PER_TURN)\n",
    "\n",
    "    result = compute_legacy_kn_per_turn(\n",
    "        df_abs_turns=df_abs[:n_samp].reshape(shape),\n",
    "        df_cmp_turns=df_cmp[:n_samp].reshape(shape),\n",
    "        t_turns=time[:n_samp].reshape(shape),\n",
    "        I_turns=current[:n_samp].reshape(shape),\n",
    "        kn=kn,\n",
    "        Rref_m=R_REF_M,\n",
    "        magnet_order=MAGNET_ORDER,\n",
    "        options=OPTIONS,\n",
    "    )\n",
    "    return result, n_turns\n",
    "\n",
    "\n",
    "# Process all runs, store per-turn rows with metadata\n",
    "rows = []\n",
    "for run_id, (fp, cp) in enumerate(zip(flux_files, current_files)):\n",
    "    result, n_turns = process_run(fp, cp)\n",
    "\n",
    "    C_merged, _ = merge_coefficients(\n",
    "        C_abs=result.C_abs, C_cmp=result.C_cmp,\n",
    "        magnet_order=MAGNET_ORDER, mode=\"abs_upto_m_cmp_above\",\n",
    "    )\n",
    "\n",
    "    for t in range(n_turns):\n",
    "        Bm = C_merged[t, MAGNET_ORDER - 1].real\n",
    "        row = {\n",
    "            \"run_id\": run_id,\n",
    "            \"turn_in_run\": t,\n",
    "            \"I_mean_A\": result.I_mean_A[t],\n",
    "        }\n",
    "        for i, n in enumerate(result.orders):\n",
    "            C = C_merged[t, i]\n",
    "            if n <= MAGNET_ORDER:\n",
    "                row[f\"B{n}_T\"] = C.real\n",
    "                row[f\"A{n}_T\"] = C.imag\n",
    "            else:\n",
    "                if abs(Bm) > 1e-30:\n",
    "                    row[f\"b{n}_units\"] = C.real / Bm * 10000.0\n",
    "                    row[f\"a{n}_units\"] = C.imag / Bm * 10000.0\n",
    "                else:\n",
    "                    row[f\"b{n}_units\"] = np.nan\n",
    "                    row[f\"a{n}_units\"] = np.nan\n",
    "        rows.append(row)\n",
    "\n",
    "computed_df = pd.DataFrame(rows)\n",
    "print(f\"Processed {n_runs} runs -> {len(computed_df)} total turns\")\n",
    "print(f\"  Turns per run: {computed_df.groupby('run_id').size().unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10-alignment-header",
   "metadata": {},
   "source": "---\n## Turn Selection & Alignment\n\nThe legacy software keeps the first measurement turns from each run, but the\nnumber of turns **varies by run** (the reference has 7 for the first run,\n5 for the last, and 6 for all others). We cannot assume a fixed count.\n\n**Strategy**:\n1. Detect run boundaries in the reference by finding current jumps (>2 A).\n2. For each reference run group, take the same number of turns from the\n   corresponding computed run (first N turns).\n3. Verify alignment by checking B2 match."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11-alignment",
   "metadata": {},
   "outputs": [],
   "source": "# -- Detect run boundaries in the reference --\n# A new run starts when the current jumps by more than 2 A.\nref_I = ref_df[I_col].values.astype(float)\nref_b2 = ref_df[main_col].values.astype(float)\n\nref_run_starts = [0]\nfor i in range(1, len(ref_I)):\n    if abs(ref_I[i] - ref_I[i - 1]) > 2.0:\n        ref_run_starts.append(i)\nref_run_starts.append(len(ref_df))  # sentinel\n\nn_ref_runs = len(ref_run_starts) - 1\nprint(f\"Detected {n_ref_runs} runs in reference (expected {n_runs})\")\n\n# Show turns-per-run distribution\nref_turns_per_run = [ref_run_starts[i+1] - ref_run_starts[i] for i in range(n_ref_runs)]\nfrom collections import Counter\nprint(f\"Turns per run: {dict(Counter(ref_turns_per_run))}\")\n\nassert n_ref_runs == n_runs, (\n    f\"Reference has {n_ref_runs} runs but we have {n_runs} flux files\"\n)\n\n# -- Align: for each reference run, take the first N computed turns --\naligned_indices = []\nalignment_log = []\n\nfor run_id in range(n_runs):\n    ref_start = ref_run_starts[run_id]\n    ref_end = ref_run_starts[run_id + 1]\n    n_ref_turns = ref_end - ref_start\n\n    run_mask = computed_df[\"run_id\"] == run_id\n    run_global_indices = computed_df[run_mask].index.tolist()\n\n    # Take the first n_ref_turns computed turns from this run\n    selected = run_global_indices[:n_ref_turns]\n\n    for local_t, gi in enumerate(selected):\n        ref_row = ref_start + local_t\n        comp_b2 = computed_df.loc[gi, \"B2_T\"]\n        ref_val = ref_b2[ref_row]\n        rel = abs(comp_b2 - ref_val) / max(abs(ref_val), 1e-30)\n        aligned_indices.append(gi)\n\n        alignment_log.append({\n            \"ref_row\": ref_row,\n            \"run_id\": run_id,\n            \"turn_in_run\": computed_df.loc[gi, \"turn_in_run\"],\n            \"B2_ref\": ref_val,\n            \"B2_comp\": comp_b2,\n            \"rel_diff\": rel,\n        })\n\naligned_df = computed_df.iloc[aligned_indices].reset_index(drop=True)\nalign_log_df = pd.DataFrame(alignment_log)\n\n# Diagnostics\nmax_rel = align_log_df[\"rel_diff\"].max()\nmedian_rel = align_log_df[\"rel_diff\"].median()\nn_good = (align_log_df[\"rel_diff\"] < 1e-4).sum()\n\nprint(f\"\\nAligned {len(aligned_df)} / {len(ref_df)} reference turns\")\nprint(f\"  B2 max  rel err: {max_rel:.2e}\")\nprint(f\"  B2 median rel  : {median_rel:.2e}\")\nprint(f\"  B2 < 1e-4 rel  : {n_good} / {len(aligned_df)}\")\n\n# Show worst matches\nworst = align_log_df.nlargest(5, \"rel_diff\")\nprint(\"\\nWorst 5 B2 matches:\")\ndisplay(worst)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12-parity-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Parity Results\n",
    "\n",
    "Compare computed harmonics against reference at multiple current thresholds.\n",
    "\n",
    "**Status thresholds** (on max relative difference):\n",
    "\n",
    "| Status | Max |rel diff| |\n",
    "|--------|----------------|\n",
    "| EXCELLENT | < 1e-6 |\n",
    "| GOOD | < 1e-3 |\n",
    "| CLOSE | < 0.1 |\n",
    "| MARGINAL | < 1.0 |\n",
    "| MISMATCH | >= 1.0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13-parity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_ref_col(n, component=\"B\"):\n",
    "    \"\"\"Find reference column for harmonic n.\"\"\"\n",
    "    for pat in [\n",
    "        f\"{component}{n} (T)\", f\"{component}{n}(T)\",\n",
    "        f\"{component.lower()}{n} (units)\", f\"{component.lower()}{n}(units)\",\n",
    "        f\"{component}{n} (units)\", f\"{component}{n}(units)\",\n",
    "        f\"{component}{n}\",\n",
    "    ]:\n",
    "        if pat in ref_df.columns:\n",
    "            return pat\n",
    "    return None\n",
    "\n",
    "\n",
    "def classify(max_rel):\n",
    "    if max_rel < 1e-6:   return \"EXCELLENT\"\n",
    "    if max_rel < 1e-3:   return \"GOOD\"\n",
    "    if max_rel < 0.1:    return \"CLOSE\"\n",
    "    if max_rel < 1.0:    return \"MARGINAL\"\n",
    "    return \"MISMATCH\"\n",
    "\n",
    "\n",
    "def parity_table(mask, label):\n",
    "    \"\"\"Compute parity for turns selected by mask.\"\"\"\n",
    "    n_sel = mask.sum()\n",
    "    results = []\n",
    "    for n in range(1, 16):\n",
    "        ref_col = _find_ref_col(n, \"B\")\n",
    "        if ref_col is None:\n",
    "            continue\n",
    "        comp_col = f\"B{n}_T\" if n <= MAGNET_ORDER else f\"b{n}_units\"\n",
    "        if comp_col not in aligned_df.columns:\n",
    "            continue\n",
    "\n",
    "        cv = aligned_df.loc[mask, comp_col].values\n",
    "        rv = ref_df.loc[mask, ref_col].values.astype(float)\n",
    "\n",
    "        ad = np.abs(cv - rv)\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            rd = np.where(np.abs(rv) > 1e-30, np.abs((cv - rv) / rv), 0.0)\n",
    "\n",
    "        results.append({\n",
    "            \"n\": n,\n",
    "            \"ref_col\": ref_col,\n",
    "            \"comp_col\": comp_col,\n",
    "            \"max_abs\": np.max(ad),\n",
    "            \"max_rel\": float(np.nanmax(rd)),\n",
    "            \"rms\": np.sqrt(np.mean(ad**2)),\n",
    "            \"status\": classify(float(np.nanmax(rd))),\n",
    "        })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Get current values for filtering\n",
    "I_aligned = aligned_df[\"I_mean_A\"].values\n",
    "I_ref_aligned = ref_df[I_col].values.astype(float) if I_col else I_aligned\n",
    "\n",
    "# Parity tables at different current thresholds\n",
    "thresholds = [(\"All turns\", np.ones(len(aligned_df), dtype=bool)),\n",
    "              (\"|I| >= 10 A\", np.abs(I_ref_aligned) >= 10),\n",
    "              (\"|I| >= 50 A\", np.abs(I_ref_aligned) >= 50),\n",
    "              (\"|I| >= 100 A\", np.abs(I_ref_aligned) >= 100)]\n",
    "\n",
    "for label, mask in thresholds:\n",
    "    tbl = parity_table(mask, label)\n",
    "    n_sel = mask.sum()\n",
    "    print(f\"\\n{'=' * 100}\")\n",
    "    print(f\"  {label}  ({n_sel} turns)\")\n",
    "    print(f\"{'=' * 100}\")\n",
    "    print(f\"{'n':>3} {'ref_col':>20} {'comp_col':>16} {'max|diff|':>14} {'max|rel|':>14} {'RMS':>14} {'status':>12}\")\n",
    "    print(\"-\" * 100)\n",
    "    for _, r in tbl.iterrows():\n",
    "        print(f\"{r['n']:3.0f} {r['ref_col']:>20s} {r['comp_col']:>16s} \"\n",
    "              f\"{r['max_abs']:14.6e} {r['max_rel']:14.6e} {r['rms']:14.6e} {r['status']:>12s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14-error-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Error Analysis\n",
    "\n",
    "Detailed breakdown of where and why residual differences occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15-error-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# --- (a) B2 time series ---\n",
    "ax = axes[0, 0]\n",
    "rv = ref_df[main_col].values[:len(aligned_df)].astype(float)\n",
    "cv = aligned_df[\"B2_T\"].values\n",
    "ax.plot(rv, \"b-\", label=\"Reference\", alpha=0.7)\n",
    "ax.plot(cv, \"r--\", label=\"Computed\", alpha=0.7)\n",
    "ax.set_xlabel(\"Turn\")\n",
    "ax.set_ylabel(main_col)\n",
    "ax.set_title(f\"Main Field (n={MAGNET_ORDER}): Time Series\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (b) b3 difference histogram (|I| >= 50 A) ---\n",
    "ax = axes[0, 1]\n",
    "b3_ref_col = _find_ref_col(3, \"B\") or _find_ref_col(3, \"b\")\n",
    "if b3_ref_col and \"b3_units\" in aligned_df.columns:\n",
    "    hi_mask = np.abs(I_ref_aligned) >= 50\n",
    "    if hi_mask.sum() > 0:\n",
    "        b3_diff = aligned_df.loc[hi_mask, \"b3_units\"].values - ref_df.loc[hi_mask, b3_ref_col].values.astype(float)\n",
    "        ax.hist(b3_diff, bins=40, edgecolor=\"black\", alpha=0.7, color=\"steelblue\")\n",
    "        ax.axvline(0, color=\"r\", linestyle=\"--\")\n",
    "        within_001 = (np.abs(b3_diff) < 0.001).sum()\n",
    "        ax.set_title(f\"b3 diff (|I|>=50A): {within_001}/{len(b3_diff)} within 0.001\")\n",
    "    else:\n",
    "        ax.set_title(\"b3 diff: no turns at |I|>=50A\")\n",
    "else:\n",
    "    ax.set_title(\"b3 column not found\")\n",
    "ax.set_xlabel(\"b3 difference (units)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (c) Worst-turn analysis (B2) ---\n",
    "ax = axes[1, 0]\n",
    "b2_rel = np.abs(cv - rv) / np.maximum(np.abs(rv), 1e-30)\n",
    "ax.semilogy(b2_rel, \".\", markersize=4)\n",
    "ax.axhline(1e-6, color=\"g\", linestyle=\"--\", label=\"1 ppm\")\n",
    "ax.set_xlabel(\"Turn\")\n",
    "ax.set_ylabel(\"B2 relative difference\")\n",
    "ax.set_title(\"B2 per-turn relative error\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- (d) Per-harmonic RMS error bar chart ---\n",
    "ax = axes[1, 1]\n",
    "all_tbl = parity_table(np.ones(len(aligned_df), dtype=bool), \"all\")\n",
    "ax.bar(all_tbl[\"n\"].values, all_tbl[\"rms\"].values, color=\"teal\", edgecolor=\"black\")\n",
    "ax.set_xlabel(\"Harmonic order n\")\n",
    "ax.set_ylabel(\"RMS difference\")\n",
    "ax.set_title(\"Per-harmonic RMS error (all turns)\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Summary ---\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total aligned turns : {len(aligned_df)} / {len(ref_df)}\")\n",
    "print(f\"B2 max rel error    : {b2_rel.max():.2e}\")\n",
    "if b3_ref_col and \"b3_units\" in aligned_df.columns:\n",
    "    b3_all_diff = aligned_df[\"b3_units\"].values - ref_df[b3_ref_col].values[:len(aligned_df)].astype(float)\n",
    "    print(f\"b3 RMS (all turns)  : {np.sqrt(np.mean(b3_all_diff**2)):.6f} units\")\n",
    "    if hi_mask.sum() > 0:\n",
    "        print(f\"b3 within 0.001     : {within_001}/{len(b3_diff)} at |I|>=50A\")\n",
    "\n",
    "# Status counts\n",
    "for label, mask in thresholds:\n",
    "    tbl = parity_table(mask, label)\n",
    "    counts = tbl[\"status\"].value_counts()\n",
    "    summary = \", \".join(f\"{s}: {counts.get(s, 0)}\" for s in [\"EXCELLENT\", \"GOOD\", \"CLOSE\", \"MARGINAL\", \"MISMATCH\"])\n",
    "    print(f\"\\n{label} ({mask.sum()} turns): {summary}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}