{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Golden Standard Parity Validation\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook validates that our Python analysis pipeline produces **identical results** to the legacy C++ analyzer (ffmm framework) when processing the same raw measurement data.\n",
    "\n",
    "**Success criterion**: All harmonics must match to within numerical precision (ideally < 1e-9 relative error).\n",
    "\n",
    "## Theory Background\n",
    "\n",
    "### Rotating Coil Measurement Principle\n",
    "\n",
    "A rotating coil measures magnetic field harmonics by rotating a coil inside a magnet aperture. The induced voltage is integrated to obtain flux, which is then Fourier-transformed to extract harmonics.\n",
    "\n",
    "### Key Formulas (from ffmm C++ and Bottura PDF)\n",
    "\n",
    "1. **Drift Correction** (legacy C++ style):\n",
    "   ```\n",
    "   flux = cumsum(df - mean(df)) - mean(cumsum(df))\n",
    "   ```\n",
    "   This removes DC offset from the incremental signal and centers the integrated flux.\n",
    "\n",
    "2. **FFT Normalization**:\n",
    "   ```\n",
    "   f_n = 2 * FFT(flux)[n] / N_samples\n",
    "   ```\n",
    "   The factor of 2 accounts for the two-sided FFT spectrum.\n",
    "\n",
    "3. **Kn Calibration** (coil sensitivity):\n",
    "   ```\n",
    "   C_n = f_n / conj(kn) * Rref^(n-1)\n",
    "   ```\n",
    "   Where `kn` are complex calibration coefficients from the measurement head geometry.\n",
    "\n",
    "4. **Rotation** (phase alignment to main field):\n",
    "   ```\n",
    "   C_n_rotated = C_n * exp(-i * (n-m) * angle_m)\n",
    "   ```\n",
    "   Where `m` is the magnet order (2 for quadrupole) and `angle_m = arg(C_m)`.\n",
    "\n",
    "### Harmonic Merge Strategy\n",
    "\n",
    "- **Absolute channel (ABS)**: Direct measurement, used for main field (n ≤ m)\n",
    "- **Compensated channel (CMP)**: Bucking coil cancels main field, used for errors (n > m)\n",
    "\n",
    "For a quadrupole (m=2): Use ABS for n=1,2 and CMP for n=3,4,...,15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration\n",
    "\n",
    "Edit this cell to point to your golden standard dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET CONFIGURATION - Edit these paths for your dataset\n",
    "# =============================================================================\n",
    "\n",
    "# Path to the measurement folder (contains flux files, current files, results)\n",
    "DATASET_FOLDER = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/Central/20190718_141359_LIU\")\n",
    "\n",
    "# Path to the Kn calibration file (must match the compensation scheme used)\n",
    "# BD_AE = B-D absolute, A-E compensated (for quadrupole with 4-coil bucking)\n",
    "KN_FILE = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/COIL_PCB/PCB_DQ_5_18_7_250_47x50_Hall/Kn-Th/Kn_DQ_5_18_7_250_47x50_0001_BD_AE.txt\")\n",
    "\n",
    "# =============================================================================\n",
    "# MAGNET PARAMETERS - From the Parameters.txt file\n",
    "# =============================================================================\n",
    "\n",
    "MAGNET_ORDER = 2      # 1=dipole, 2=quadrupole, 3=sextupole, etc.\n",
    "R_REF_M = 1.0         # Reference radius in meters (affects multipole scaling)\n",
    "L_COIL_M = 1.32209    # Coil length in meters\n",
    "SHAFT_SPEED_RPM = 60  # Rotation speed (absolute value)\n",
    "\n",
    "# =============================================================================\n",
    "# CRITICAL: Samples per turn\n",
    "# =============================================================================\n",
    "# This value must match how the data was acquired!\n",
    "# For BTP8 format: typically 512 samples per revolution\n",
    "# Using the wrong value causes ~60x magnitude errors!\n",
    "\n",
    "SAMPLES_PER_TURN = 512  # CORRECT for BTP8\n",
    "\n",
    "# =============================================================================\n",
    "# ANALYSIS OPTIONS - Must match the reference (from Options column)\n",
    "# =============================================================================\n",
    "\n",
    "OPTIONS = (\"dri\", \"rot\")  # dri=drift correction, rot=rotation to main field\n",
    "\n",
    "# Output directory for comparison reports\n",
    "OUTPUT_DIR = Path(\"../../outputs/golden_runs/LIU_BTP8_20190718_141359\")\n",
    "\n",
    "print(\"Configuration loaded successfully.\")\n",
    "print(f\"  Magnet order: {MAGNET_ORDER} ({'dipole' if MAGNET_ORDER==1 else 'quadrupole' if MAGNET_ORDER==2 else 'higher'})\")\n",
    "print(f\"  Samples/turn: {SAMPLES_PER_TURN}\")\n",
    "print(f\"  Options: {OPTIONS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport json\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Add repo to path\nrepo_root = Path(\"../..\").resolve()\nif str(repo_root) not in sys.path:\n    sys.path.insert(0, str(repo_root))\n\n# Core analysis imports\nfrom rotating_coil_analyzer.analysis.kn_pipeline import (\n    load_segment_kn_txt,\n    compute_legacy_kn_per_turn,\n    merge_coefficients,\n)\n\nprint(\"All imports successful.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resolve-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve all paths\n",
    "notebook_dir = Path(\".\").resolve()\n",
    "dataset_folder = (notebook_dir / DATASET_FOLDER).resolve()\n",
    "kn_file = (notebook_dir / KN_FILE).resolve()\n",
    "output_dir = (notebook_dir / OUTPUT_DIR).resolve()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset folder: {dataset_folder}\")\n",
    "print(f\"  Exists: {dataset_folder.exists()}\")\n",
    "print(f\"Kn file: {kn_file}\")\n",
    "print(f\"  Exists: {kn_file.exists()}\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    raise FileNotFoundError(f\"Dataset folder not found: {dataset_folder}\")\n",
    "if not kn_file.exists():\n",
    "    raise FileNotFoundError(f\"Kn file not found: {kn_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reference-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load Reference Results\n",
    "\n",
    "The golden reference results were produced by the legacy C++ analyzer (ffmm framework).\n",
    "Our goal is to reproduce these exact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the reference results file\n",
    "ref_files = list(dataset_folder.glob(\"*results*.txt\"))\n",
    "ref_files = [f for f in ref_files if \"Average\" not in f.name and \"Parameters\" not in f.name]\n",
    "\n",
    "if not ref_files:\n",
    "    raise FileNotFoundError(\"No reference results file found in dataset folder\")\n",
    "\n",
    "ref_path = ref_files[0]\n",
    "print(f\"Loading reference: {ref_path.name}\")\n",
    "\n",
    "ref_df = pd.read_csv(ref_path, sep=\"\\t\")\n",
    "print(f\"\\nReference data shape: {ref_df.shape}\")\n",
    "print(f\"Number of turns: {len(ref_df)}\")\n",
    "\n",
    "# Show column names (these tell us what harmonics are available)\n",
    "harmonic_cols = [c for c in ref_df.columns if c.startswith('B') or c.startswith('A')]\n",
    "print(f\"\\nHarmonic columns: {harmonic_cols[:10]}...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the reference data structure\n",
    "print(\"Reference data summary:\")\n",
    "print(f\"  Total measurement turns: {len(ref_df)}\")\n",
    "print(f\"  Current range: [{ref_df['I FGC(A)'].min():.1f}, {ref_df['I FGC(A)'].max():.1f}] A\")\n",
    "\n",
    "# Main field range (B2 for quadrupole)\n",
    "main_col = f\"B{MAGNET_ORDER} (T)\"\n",
    "if main_col in ref_df.columns:\n",
    "    print(f\"  {main_col} range: [{ref_df[main_col].min():.6f}, {ref_df[main_col].max():.6f}] T\")\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 rows (key columns):\")\n",
    "key_cols = ['I FGC(A)', 'B1 (T)', 'B2 (T)', 'B3 (T)', 'Angle (rad)']\n",
    "key_cols = [c for c in key_cols if c in ref_df.columns]\n",
    "display(ref_df[key_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kn-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Kn Calibration Coefficients\n",
    "\n",
    "The Kn coefficients encode the coil sensitivity for each harmonic order.\n",
    "They depend on:\n",
    "- Coil geometry (radius, turns, winding pattern)\n",
    "- Compensation scheme (which coils are combined for ABS vs CMP channels)\n",
    "\n",
    "**Important**: Use the Kn file that matches the compensation scheme in your measurement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-kn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kn coefficients\n",
    "kn = load_segment_kn_txt(kn_file)\n",
    "\n",
    "print(f\"Kn loaded from: {kn_file.name}\")\n",
    "print(f\"  Harmonic orders: {list(kn.orders)}\")\n",
    "print(f\"  Number of harmonics: {len(kn.orders)}\")\n",
    "\n",
    "# Display kn magnitudes\n",
    "print(\"\\nKn coefficient magnitudes:\")\n",
    "print(f\"{'n':>3} {'|kn_abs|':>15} {'|kn_cmp|':>15} {'cmp/abs':>10}\")\n",
    "print(\"-\" * 48)\n",
    "for i, n in enumerate(kn.orders):\n",
    "    abs_mag = np.abs(kn.kn_abs[i])\n",
    "    cmp_mag = np.abs(kn.kn_cmp[i])\n",
    "    ratio = cmp_mag / abs_mag if abs_mag > 1e-30 else np.nan\n",
    "    print(f\"{n:3d} {abs_mag:15.6e} {cmp_mag:15.6e} {ratio:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raw-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Parse Raw BTP8 Flux Data\n",
    "\n",
    "### BTP8 File Format\n",
    "\n",
    "The BTP8 flux files have 4 columns:\n",
    "- Column 0: `df_abs` - Incremental flux from absolute channel (Wb)\n",
    "- Column 1: `encoder` - Encoder position (counts)\n",
    "- Column 2: `df_cmp` - Incremental flux from compensated channel (Wb)\n",
    "- Column 3: `encoder` - Encoder position (duplicate)\n",
    "\n",
    "Each row represents one sample (one angular position within a turn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-parsers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_btp8_flux_file(flux_path: Path) -> tuple:\n",
    "    \"\"\"Parse BTP8 flux file (4-column format).\n",
    "    \n",
    "    Returns:\n",
    "        df_abs: Incremental flux, absolute channel (Wb)\n",
    "        df_cmp: Incremental flux, compensated channel (Wb)\n",
    "        encoder: Encoder counts (for timing)\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(flux_path)\n",
    "    df_abs = data[:, 0]\n",
    "    encoder = data[:, 1]\n",
    "    df_cmp = data[:, 2]\n",
    "    return df_abs, df_cmp, encoder\n",
    "\n",
    "\n",
    "def parse_btp8_current_file(current_path: Path) -> np.ndarray:\n",
    "    \"\"\"Parse BTP8 current file (single column).\"\"\"\n",
    "    return np.loadtxt(current_path)\n",
    "\n",
    "\n",
    "def encoder_to_time(encoder: np.ndarray, shaft_rpm: float, \n",
    "                    encoder_res: int = 40000) -> np.ndarray:\n",
    "    \"\"\"Convert encoder counts to time in seconds.\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder counts array\n",
    "        shaft_rpm: Rotation speed in RPM\n",
    "        encoder_res: Encoder resolution (counts per revolution)\n",
    "    \"\"\"\n",
    "    counts_per_second = shaft_rpm * encoder_res / 60.0\n",
    "    return encoder / counts_per_second\n",
    "\n",
    "\n",
    "print(\"Parser functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "find-raw-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all raw data files\n",
    "flux_files = sorted(dataset_folder.glob(\"*_fluxes_Ascii.txt\"))\n",
    "current_files = sorted(dataset_folder.glob(\"*_current.txt\"))\n",
    "\n",
    "print(f\"Found {len(flux_files)} flux files and {len(current_files)} current files\")\n",
    "\n",
    "if len(flux_files) == 0:\n",
    "    raise FileNotFoundError(\"No flux files found in dataset folder\")\n",
    "\n",
    "# Show first few files\n",
    "print(\"\\nFirst 5 flux files:\")\n",
    "for f in flux_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-first-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first file to understand the data structure\n",
    "test_flux_path = flux_files[0]\n",
    "test_current_path = current_files[0]\n",
    "\n",
    "df_abs, df_cmp, encoder = parse_btp8_flux_file(test_flux_path)\n",
    "current = parse_btp8_current_file(test_current_path)\n",
    "time = encoder_to_time(encoder, SHAFT_SPEED_RPM)\n",
    "\n",
    "print(f\"File: {test_flux_path.name}\")\n",
    "print(f\"  Total samples: {len(df_abs)}\")\n",
    "print(f\"  Samples per turn: {SAMPLES_PER_TURN}\")\n",
    "print(f\"  Complete turns: {len(df_abs) // SAMPLES_PER_TURN}\")\n",
    "print(f\"\\nFlux ranges:\")\n",
    "print(f\"  df_abs: [{df_abs.min():.6e}, {df_abs.max():.6e}] Wb\")\n",
    "print(f\"  df_cmp: [{df_cmp.min():.6e}, {df_cmp.max():.6e}] Wb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Process Data and Compute Harmonics\n",
    "\n",
    "### Processing Pipeline Steps\n",
    "\n",
    "1. **Parse** raw flux and current files\n",
    "2. **Reshape** samples into turns (using SAMPLES_PER_TURN)\n",
    "3. **Drift correction** (if enabled): Remove linear drift from integrated flux\n",
    "4. **FFT**: Compute Fourier coefficients from flux\n",
    "5. **Kn application**: Scale by coil sensitivity\n",
    "6. **Rotation** (if enabled): Align phase to main field\n",
    "7. **Merge**: Combine ABS and CMP channels appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_btp8_run(flux_path: Path, current_path: Path, kn,\n",
    "                     samples_per_turn: int,\n",
    "                     shaft_rpm: float,\n",
    "                     magnet_order: int,\n",
    "                     r_ref_m: float,\n",
    "                     options: tuple):\n",
    "    \"\"\"Process a single BTP8 measurement run.\n",
    "    \n",
    "    This implements the same pipeline as the legacy C++ analyzer.\n",
    "    \n",
    "    Args:\n",
    "        flux_path: Path to flux file\n",
    "        current_path: Path to current file\n",
    "        kn: SegmentKn calibration object\n",
    "        samples_per_turn: Number of samples per revolution\n",
    "        shaft_rpm: Rotation speed\n",
    "        magnet_order: Main field order (m)\n",
    "        r_ref_m: Reference radius for multipole normalization\n",
    "        options: Tuple of enabled options (\"dri\", \"rot\", etc.)\n",
    "    \n",
    "    Returns:\n",
    "        result: KnPerTurnResult with computed harmonics\n",
    "        n_turns: Number of complete turns processed\n",
    "    \"\"\"\n",
    "    # Parse files\n",
    "    df_abs, df_cmp, encoder = parse_btp8_flux_file(flux_path)\n",
    "    current = parse_btp8_current_file(current_path)\n",
    "    time = encoder_to_time(encoder, shaft_rpm)\n",
    "    \n",
    "    # Align current to flux length (they may differ slightly)\n",
    "    n_flux = len(df_abs)\n",
    "    n_curr = len(current)\n",
    "    if n_curr != n_flux:\n",
    "        indices = np.linspace(0, n_curr - 1, n_flux).astype(int)\n",
    "        current_aligned = current[indices]\n",
    "    else:\n",
    "        current_aligned = current\n",
    "    \n",
    "    # Truncate to complete turns only\n",
    "    n_turns = n_flux // samples_per_turn\n",
    "    n_samples = n_turns * samples_per_turn\n",
    "    \n",
    "    # Reshape into (n_turns, samples_per_turn)\n",
    "    df_abs_turns = df_abs[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    df_cmp_turns = df_cmp[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    t_turns = time[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    I_turns = current_aligned[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    \n",
    "    # Run the pipeline (this is the core computation)\n",
    "    result = compute_legacy_kn_per_turn(\n",
    "        df_abs_turns=df_abs_turns,\n",
    "        df_cmp_turns=df_cmp_turns,\n",
    "        t_turns=t_turns,\n",
    "        I_turns=I_turns,\n",
    "        kn=kn,\n",
    "        Rref_m=r_ref_m,\n",
    "        magnet_order=magnet_order,\n",
    "        absCalib=1.0,\n",
    "        options=options,\n",
    "    )\n",
    "    \n",
    "    return result, n_turns\n",
    "\n",
    "\n",
    "print(\"Processing function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-all-runs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all runs and collect results\n",
    "print(f\"Processing {len(flux_files)} measurement runs...\")\n",
    "print(f\"Options: {OPTIONS}\")\n",
    "print(f\"Samples per turn: {SAMPLES_PER_TURN}\")\n",
    "print()\n",
    "\n",
    "all_results = []\n",
    "total_turns = 0\n",
    "\n",
    "for i, (flux_path, current_path) in enumerate(zip(flux_files, current_files)):\n",
    "    result, n_turns = process_btp8_run(\n",
    "        flux_path=flux_path,\n",
    "        current_path=current_path,\n",
    "        kn=kn,\n",
    "        samples_per_turn=SAMPLES_PER_TURN,\n",
    "        shaft_rpm=SHAFT_SPEED_RPM,\n",
    "        magnet_order=MAGNET_ORDER,\n",
    "        r_ref_m=R_REF_M,\n",
    "        options=OPTIONS,\n",
    "    )\n",
    "    all_results.append(result)\n",
    "    total_turns += n_turns\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"  Processed {i + 1}/{len(flux_files)} runs...\")\n",
    "\n",
    "print(f\"\\nDone! Processed {total_turns} total turns from {len(flux_files)} runs.\")\n",
    "print(f\"Reference has {len(ref_df)} turns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Compare with Reference\n",
    "\n",
    "Now we compare our computed harmonics with the golden reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-comparison-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame with all computed harmonics\n",
    "rows = []\n",
    "turn_idx = 0\n",
    "\n",
    "for result in all_results:\n",
    "    # Merge coefficients: ABS for n<=m, CMP for n>m\n",
    "    C_merged, _ = merge_coefficients(\n",
    "        C_abs=result.C_abs,\n",
    "        C_cmp=result.C_cmp,\n",
    "        magnet_order=MAGNET_ORDER,\n",
    "        mode=\"abs_upto_m_cmp_above\",\n",
    "    )\n",
    "    \n",
    "    for t in range(result.C_abs.shape[0]):\n",
    "        row = {\"turn_idx\": turn_idx}\n",
    "        for i, n in enumerate(result.orders):\n",
    "            row[f\"B{n}\"] = np.real(C_merged[t, i])\n",
    "            row[f\"A{n}\"] = np.imag(C_merged[t, i])\n",
    "        rows.append(row)\n",
    "        turn_idx += 1\n",
    "\n",
    "computed_df = pd.DataFrame(rows)\n",
    "print(f\"Computed results: {len(computed_df)} turns\")\n",
    "print(f\"Reference results: {len(ref_df)} turns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-harmonics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare harmonics turn by turn\n",
    "n_compare = min(len(computed_df), len(ref_df))\n",
    "print(f\"Comparing first {n_compare} turns...\\n\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"HARMONIC COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'n':>3} {'Max |Diff|':>15} {'Max |Rel Diff|':>15} {'Status':>12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for n in range(1, 16):\n",
    "    comp_col = f\"B{n}\"\n",
    "    ref_col = f\"B{n} (T)\"\n",
    "    \n",
    "    if comp_col not in computed_df.columns or ref_col not in ref_df.columns:\n",
    "        continue\n",
    "    \n",
    "    comp_vals = computed_df[comp_col].values[:n_compare]\n",
    "    ref_vals = ref_df[ref_col].values[:n_compare]\n",
    "    \n",
    "    # Absolute difference\n",
    "    abs_diff = np.abs(comp_vals - ref_vals)\n",
    "    max_abs_diff = np.max(abs_diff)\n",
    "    \n",
    "    # Relative difference (avoid division by zero)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        rel_diff = np.abs((comp_vals - ref_vals) / ref_vals)\n",
    "        rel_diff = np.where(np.isfinite(rel_diff), rel_diff, 0)\n",
    "    max_rel_diff = np.max(rel_diff)\n",
    "    \n",
    "    # Determine status\n",
    "    if max_rel_diff < 1e-6:\n",
    "        status = \"EXCELLENT\"\n",
    "    elif max_rel_diff < 1e-3:\n",
    "        status = \"GOOD\"\n",
    "    elif max_rel_diff < 0.1:\n",
    "        status = \"CLOSE\"\n",
    "    else:\n",
    "        status = \"MISMATCH\"\n",
    "    \n",
    "    print(f\"{n:3d} {max_abs_diff:15.6e} {max_rel_diff:15.6e} {status:>12}\")\n",
    "    \n",
    "    comparison_results.append({\n",
    "        \"n\": n,\n",
    "        \"max_abs_diff\": max_abs_diff,\n",
    "        \"max_rel_diff\": max_rel_diff,\n",
    "        \"status\": status,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison for main field (B2 for quadrupole)\n",
    "main_n = MAGNET_ORDER\n",
    "comp_col = f\"B{main_n}\"\n",
    "ref_col = f\"B{main_n} (T)\"\n",
    "\n",
    "print(f\"\\nDetailed comparison for main field (n={main_n}):\")\n",
    "print(f\"{'Turn':>6} {'Computed':>16} {'Reference':>16} {'Diff':>16} {'Rel Diff':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i in range(min(10, n_compare)):\n",
    "    comp_val = computed_df[comp_col].iloc[i]\n",
    "    ref_val = ref_df[ref_col].iloc[i]\n",
    "    diff = comp_val - ref_val\n",
    "    rel_diff = diff / ref_val if abs(ref_val) > 1e-20 else 0\n",
    "    print(f\"{i:6d} {comp_val:16.9e} {ref_val:16.9e} {diff:16.9e} {rel_diff:12.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plots-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot computed vs reference for main field\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# B2 time series\n",
    "ax = axes[0, 0]\n",
    "ax.plot(ref_df[f\"B{MAGNET_ORDER} (T)\"].values[:n_compare], 'b-', label='Reference', alpha=0.7)\n",
    "ax.plot(computed_df[f\"B{MAGNET_ORDER}\"].values[:n_compare], 'r--', label='Computed', alpha=0.7)\n",
    "ax.set_xlabel('Turn')\n",
    "ax.set_ylabel(f'B{MAGNET_ORDER} (T)')\n",
    "ax.set_title(f'Main Field (n={MAGNET_ORDER}): Time Series')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# B2 scatter (computed vs reference)\n",
    "ax = axes[0, 1]\n",
    "ref_vals = ref_df[f\"B{MAGNET_ORDER} (T)\"].values[:n_compare]\n",
    "comp_vals = computed_df[f\"B{MAGNET_ORDER}\"].values[:n_compare]\n",
    "ax.scatter(ref_vals, comp_vals, alpha=0.5, s=10)\n",
    "ax.plot([ref_vals.min(), ref_vals.max()], [ref_vals.min(), ref_vals.max()], 'k--', label='Perfect match')\n",
    "ax.set_xlabel('Reference (T)')\n",
    "ax.set_ylabel('Computed (T)')\n",
    "ax.set_title(f'B{MAGNET_ORDER}: Computed vs Reference')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Difference histogram\n",
    "ax = axes[1, 0]\n",
    "diff = comp_vals - ref_vals\n",
    "ax.hist(diff, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='r', linestyle='--', label='Zero')\n",
    "ax.set_xlabel('Difference (T)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title(f'B{MAGNET_ORDER}: Difference Distribution')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Relative difference by harmonic\n",
    "ax = axes[1, 1]\n",
    "harmonics = [r['n'] for r in comparison_results]\n",
    "rel_diffs = [r['max_rel_diff'] for r in comparison_results]\n",
    "colors = ['green' if d < 1e-3 else 'orange' if d < 0.1 else 'red' for d in rel_diffs]\n",
    "ax.bar(harmonics, rel_diffs, color=colors, edgecolor='black')\n",
    "ax.axhline(1e-3, color='g', linestyle='--', label='Good threshold')\n",
    "ax.axhline(0.1, color='orange', linestyle='--', label='Close threshold')\n",
    "ax.set_xlabel('Harmonic Order n')\n",
    "ax.set_ylabel('Max Relative Difference')\n",
    "ax.set_title('Parity Check by Harmonic')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'parity_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPlot saved to: {output_dir / 'parity_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gui-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. How to Replicate Using the GUI\n",
    "\n",
    "This section explains step-by-step how to reproduce these results using the graphical user interface.\n",
    "\n",
    "### Step 1: Launch the GUI\n",
    "\n",
    "```bash\n",
    "cd rotating_coil_analyzer\n",
    "python -m rotating_coil_analyzer.gui.app\n",
    "```\n",
    "\n",
    "### Step 2: File Browser Tab\n",
    "\n",
    "1. Navigate to your dataset folder (e.g., `golden_standards/golden_standard_01_LIU_BTP8/Central/20190718_141359_LIU`)\n",
    "2. The file browser will show all flux files, current files, and results files\n",
    "3. Select the files you want to analyze\n",
    "\n",
    "### Step 3: Run Preview Tab\n",
    "\n",
    "1. Load a flux file to preview the raw data\n",
    "2. Verify the data looks correct (no obvious artifacts)\n",
    "3. Check that the number of samples matches expectations\n",
    "\n",
    "### Step 4: Coil Calibration Tab\n",
    "\n",
    "1. **Load Kn File**: Click \"Load Kn TXT\" and select the appropriate Kn file:\n",
    "   - For BD_AE compensation: `Kn_DQ_5_18_7_250_47x50_0001_BD_AE.txt`\n",
    "   - For A_ABCD compensation: `Kn_DQ_5_18_7_250_47x50_0001_A_ABCD.txt`\n",
    "\n",
    "2. **Alternative - Compute from Head CSV**:\n",
    "   - Load the measurement head geometry CSV\n",
    "   - Select the absolute and compensated channel connections\n",
    "   - Click \"Compute Kn\" to generate calibration coefficients\n",
    "\n",
    "3. Verify the Kn values are loaded correctly (check the table display)\n",
    "\n",
    "### Step 5: Harmonic Merge Tab\n",
    "\n",
    "1. **Set Magnet Order**: Enter `2` for quadrupole\n",
    "2. **Set Reference Radius**: Enter `1.0` m (or as specified in Parameters.txt)\n",
    "3. **Select Merge Mode**: Choose \"ABS up to m, CMP above\"\n",
    "   - This uses ABS channel for n ≤ 2 (main field)\n",
    "   - Uses CMP channel for n > 2 (error harmonics)\n",
    "4. **Set Compensation Scheme**: Enter \"BD_AE\" (for documentation)\n",
    "\n",
    "### Step 6: Plots Tab\n",
    "\n",
    "1. **Set Analysis Options**:\n",
    "   - Enable \"Drift Correction\" (dri)\n",
    "   - Enable \"Rotation\" (rot)\n",
    "   - Disable other options unless needed\n",
    "\n",
    "2. **Set Samples Per Turn**: Enter `512` (critical for BTP8 format!)\n",
    "\n",
    "3. **Run Analysis**: Click \"Compute\" to process all selected runs\n",
    "\n",
    "4. **View Results**: The plots will show the computed harmonics\n",
    "\n",
    "5. **Export**: Click \"Export CSV\" to save results in the standard format\n",
    "\n",
    "### Verification\n",
    "\n",
    "Compare your exported CSV with the reference results file:\n",
    "- B2 values should match to within 0.1%\n",
    "- Higher harmonics (B3-B15) should match to within a few percent\n",
    "- Any large discrepancies indicate a configuration mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export computed results\n",
    "computed_path = output_dir / \"computed_results.csv\"\n",
    "computed_df.to_csv(computed_path, index=False)\n",
    "print(f\"Computed results saved to: {computed_path}\")\n",
    "\n",
    "# Export comparison summary\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_path = output_dir / \"comparison_summary.csv\"\n",
    "comparison_df.to_csv(comparison_path, index=False)\n",
    "print(f\"Comparison summary saved to: {comparison_path}\")\n",
    "\n",
    "# Export provenance metadata\n",
    "metadata = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"dataset_folder\": str(dataset_folder),\n",
    "    \"kn_file\": str(kn_file),\n",
    "    \"magnet_order\": MAGNET_ORDER,\n",
    "    \"r_ref_m\": R_REF_M,\n",
    "    \"samples_per_turn\": SAMPLES_PER_TURN,\n",
    "    \"options\": OPTIONS,\n",
    "    \"n_computed_turns\": len(computed_df),\n",
    "    \"n_reference_turns\": len(ref_df),\n",
    "}\n",
    "\n",
    "metadata_path = output_dir / \"provenance.json\"\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Provenance metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 80)\n",
    "print(\"GOLDEN STANDARD PARITY VALIDATION - FINAL REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerated: {datetime.now().isoformat()}\")\n",
    "print(f\"\\nDataset: {dataset_folder.name}\")\n",
    "print(f\"Kn file: {kn_file.name}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Magnet order: {MAGNET_ORDER}\")\n",
    "print(f\"  Reference radius: {R_REF_M} m\")\n",
    "print(f\"  Samples per turn: {SAMPLES_PER_TURN}\")\n",
    "print(f\"  Options: {OPTIONS}\")\n",
    "\n",
    "print(f\"\\nData processed:\")\n",
    "print(f\"  Computed turns: {len(computed_df)}\")\n",
    "print(f\"  Reference turns: {len(ref_df)}\")\n",
    "print(f\"  Compared turns: {n_compare}\")\n",
    "\n",
    "print(f\"\\nParity Results:\")\n",
    "excellent = sum(1 for r in comparison_results if r['status'] == 'EXCELLENT')\n",
    "good = sum(1 for r in comparison_results if r['status'] == 'GOOD')\n",
    "close = sum(1 for r in comparison_results if r['status'] == 'CLOSE')\n",
    "mismatch = sum(1 for r in comparison_results if r['status'] == 'MISMATCH')\n",
    "\n",
    "print(f\"  EXCELLENT (< 1e-6 rel): {excellent} harmonics\")\n",
    "print(f\"  GOOD (< 1e-3 rel):      {good} harmonics\")\n",
    "print(f\"  CLOSE (< 0.1 rel):      {close} harmonics\")\n",
    "print(f\"  MISMATCH (>= 0.1 rel):  {mismatch} harmonics\")\n",
    "\n",
    "if mismatch == 0:\n",
    "    print(\"\\n\" + \"*\" * 80)\n",
    "    print(\"VALIDATION PASSED: All harmonics match within acceptable tolerance!\")\n",
    "    print(\"*\" * 80)\n",
    "else:\n",
    "    print(\"\\n\" + \"!\" * 80)\n",
    "    print(f\"VALIDATION WARNING: {mismatch} harmonics have significant mismatch.\")\n",
    "    print(\"Review the comparison details above for debugging.\")\n",
    "    print(\"!\" * 80)\n",
    "\n",
    "print(f\"\\nOutput files:\")\n",
    "print(f\"  {computed_path}\")\n",
    "print(f\"  {comparison_path}\")\n",
    "print(f\"  {metadata_path}\")\n",
    "print(f\"  {output_dir / 'parity_comparison.png'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}