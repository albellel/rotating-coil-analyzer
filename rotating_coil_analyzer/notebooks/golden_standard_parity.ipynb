{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# Golden Standard Parity Validation -- LIU BTP8 Integral Coil\n\n## Purpose\n\nThis notebook validates that our Python analysis pipeline produces **identical results** to the legacy C++ analyzer (ffmm framework) when processing the same raw measurement data.\n\n**Dataset:** LIU BTP8, **Integral** coil, session `20190717_161332`\n**Compensation scheme:** A (absolute) / A-B-C+D (compensated)\n\n**Success criterion**: All harmonics must match to within numerical precision (ideally < 1e-9 relative error).\n\n## Theory Background\n\n### Rotating Coil Measurement Principle\n\nA rotating coil measures magnetic field harmonics by rotating a coil inside a magnet aperture. The induced voltage is integrated to obtain flux, which is then Fourier-transformed to extract harmonics.\n\n### Key Formulas (from ffmm C++ and Bottura PDF)\n\n1. **Drift Correction** (legacy C++ style):\n   ```\n   flux = cumsum(df - mean(df)) - mean(cumsum(df))\n   ```\n   This removes DC offset from the incremental signal and centers the integrated flux.\n\n2. **FFT Normalization**:\n   ```\n   f_n = 2 * FFT(flux)[n] / N_samples\n   ```\n   The factor of 2 accounts for the two-sided FFT spectrum.\n\n3. **Kn Calibration** (coil sensitivity):\n   ```\n   C_n = f_n / conj(kn) * Rref^(n-1)\n   ```\n   Where `kn` are complex calibration coefficients from the measurement head geometry.\n\n4. **Rotation** (phase alignment to main field):\n   ```\n   C_n_rotated = C_n * exp(-i * (n-m) * angle_m)\n   ```\n   Where `m` is the magnet order (2 for quadrupole) and `angle_m = arg(C_m)`.\n\n5. **Normalization** (to relative units):\n   ```\n   c_n = C_n / C_m * 10000\n   ```\n   Where `C_m` is the main-field harmonic. Result in \"units\" (1 unit = 10^-4 of main field).\n\n### Harmonic Merge Strategy\n\n- **Absolute channel (ABS)**: Single coil A -- used for main field (n <= m)\n- **Compensated channel (CMP)**: Bucking combination A-B-C+D -- used for errors (n > m)\n\nFor a quadrupole (m=2): Use ABS for n=1,2 and CMP for n=3,4,...,15"
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration\n",
    "\n",
    "Edit this cell to point to your golden standard dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\n\n# =============================================================================\n# DATASET CONFIGURATION\n# =============================================================================\n\n# Integral coil dataset (LIU BTP8 quadrupole, session 20190717_161332)\nDATASET_FOLDER = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/Integral/20190717_161332_LIU\")\n\n# Kn calibration file -- R45_PCB_N1: A (absolute), A-B-C+D (compensated)\n# This is the correct Kn for this dataset (confirmed by Parameters.txt \"shaft: R45_PCB_N1\"\n# and by parity matching: B2 matches to 0.5 ppm with this file).\nKN_FILE = Path(\"../../golden_standards/golden_standard_01_LIU_BTP8/COIL_PCB/Kn_R45_PCB_N1_0001_A_ABCD.txt\")\n\n# =============================================================================\n# MAGNET PARAMETERS  (from BTP8_20190717_161332_Parameters.txt)\n# =============================================================================\n\nMAGNET_ORDER = 2       # Quadrupole\nR_REF_M = 0.059        # Reference radius [m] (59 mm)\nL_COIL_M = 1.32209     # Coil length [m]\nSHAFT_SPEED_RPM = 60   # Rotation speed (absolute value)\n\n# =============================================================================\n# CRITICAL: Samples per turn\n# =============================================================================\n# BTP8 format: 512 samples per revolution.\n# Using the wrong value causes ~60x magnitude errors!\nSAMPLES_PER_TURN = 512\n\n# =============================================================================\n# ANALYSIS OPTIONS\n# =============================================================================\n# The legacy reference uses a MIXED output format:\n#   B1 (T), B2 (T)     -> Tesla (absolute field, post-rotation)\n#   b3..b15 (units)     -> normalised (= Cn / Cm * 10000)\n#   Angle (rad)         -> arg(C_m) / m  (rotation angle, pre-rotation)\n#\n# We run WITHOUT \"nor\" to keep harmonics in Tesla, then manually normalise\n# n > m for comparison with the reference b_n(units).\nOPTIONS = (\"dri\", \"rot\", \"cel\", \"fed\")\n\n# Number of measurement turns per run (from Parameters.Measurement.turns)\n# Flux files contain ~14 turns, but only 6 are actual measurement turns.\nMEAS_TURNS_PER_RUN = 6\n\n# Output directory for comparison reports\nOUTPUT_DIR = Path(\"../../outputs/golden_runs/LIU_BTP8_Integral_20190717_161332\")\n\nprint(\"Configuration loaded successfully.\")\nprint(f\"  Coil type   : Integral (A / A-B-C+D)\")\nprint(f\"  Kn file     : {KN_FILE.name}\")\nprint(f\"  Magnet order: {MAGNET_ORDER} (quadrupole)\")\nprint(f\"  R_ref       : {R_REF_M} m\")\nprint(f\"  Samples/turn: {SAMPLES_PER_TURN}\")\nprint(f\"  Options     : {OPTIONS}\")\nprint(f\"  Meas turns  : {MEAS_TURNS_PER_RUN} per run\")"
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nimport json\nfrom datetime import datetime, timezone\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Add repo to path\nrepo_root = Path(\"../..\").resolve()\nif str(repo_root) not in sys.path:\n    sys.path.insert(0, str(repo_root))\n\n# Core analysis imports\nfrom rotating_coil_analyzer.analysis.kn_pipeline import (\n    load_segment_kn_txt,\n    compute_legacy_kn_per_turn,\n    merge_coefficients,\n)\n\nprint(\"All imports successful.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resolve-paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve all paths\n",
    "notebook_dir = Path(\".\").resolve()\n",
    "dataset_folder = (notebook_dir / DATASET_FOLDER).resolve()\n",
    "kn_file = (notebook_dir / KN_FILE).resolve()\n",
    "output_dir = (notebook_dir / OUTPUT_DIR).resolve()\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset folder: {dataset_folder}\")\n",
    "print(f\"  Exists: {dataset_folder.exists()}\")\n",
    "print(f\"Kn file: {kn_file}\")\n",
    "print(f\"  Exists: {kn_file.exists()}\")\n",
    "\n",
    "if not dataset_folder.exists():\n",
    "    raise FileNotFoundError(f\"Dataset folder not found: {dataset_folder}\")\n",
    "if not kn_file.exists():\n",
    "    raise FileNotFoundError(f\"Kn file not found: {kn_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reference-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Load Reference Results\n",
    "\n",
    "The golden reference results were produced by the legacy C++ analyzer (ffmm framework).\n",
    "Our goal is to reproduce these exact values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the reference results file\n",
    "ref_files = list(dataset_folder.glob(\"*results*.txt\"))\n",
    "ref_files = [f for f in ref_files if \"Average\" not in f.name and \"Parameters\" not in f.name]\n",
    "\n",
    "if not ref_files:\n",
    "    raise FileNotFoundError(\"No reference results file found in dataset folder\")\n",
    "\n",
    "ref_path = ref_files[0]\n",
    "print(f\"Loading reference: {ref_path.name}\")\n",
    "\n",
    "ref_df = pd.read_csv(ref_path, sep=\"\\t\")\n",
    "print(f\"\\nReference data shape: {ref_df.shape}\")\n",
    "print(f\"Number of turns: {len(ref_df)}\")\n",
    "\n",
    "# Show column names (these tell us what harmonics are available)\n",
    "harmonic_cols = [c for c in ref_df.columns if c.startswith('B') or c.startswith('A')]\n",
    "print(f\"\\nHarmonic columns: {harmonic_cols[:10]}...\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze-reference",
   "metadata": {},
   "outputs": [],
   "source": "# Understand the reference data structure\nprint(\"Reference data summary:\")\nprint(f\"  Total measurement turns: {len(ref_df)}\")\n\n# Current column (may be 'I(A)' or 'I FGC(A)')\nI_col = next((c for c in ref_df.columns if \"I\" in c and \"A\" in c), None)\nif I_col:\n    print(f\"  Current column: '{I_col}'\")\n    print(f\"  Current range: [{ref_df[I_col].min():.1f}, {ref_df[I_col].max():.1f}] A\")\n\n# Main field (B2 for quadrupole, in Tesla)\nmain_col = f\"B{MAGNET_ORDER} (T)\"\nif main_col not in ref_df.columns:\n    main_col = f\"B{MAGNET_ORDER}(T)\"\nif main_col in ref_df.columns:\n    print(f\"  {main_col} range: [{ref_df[main_col].min():.6e}, {ref_df[main_col].max():.6e}] T\")\n\n# Detect column naming convention (Tesla vs normalized units)\nhas_units_cols = any(\"(units)\" in c for c in ref_df.columns)\nhas_tesla_cols = any(\"B3 (T)\" in c or \"B3(T)\" in c for c in ref_df.columns)\nprint(f\"\\n  Column convention: {'normalized (units)' if has_units_cols else 'Tesla'}\")\nprint(f\"  Options in data: {ref_df['Options'].iloc[0].strip() if 'Options' in ref_df.columns else 'N/A'}\")\n\n# Show first few rows\nprint(\"\\nFirst 3 rows (key columns):\")\nkey_cols = [c for c in ref_df.columns if any(\n    k in c for k in [\"I(A)\", \"I FGC\", \"B1\", \"B2\", \"b3\", \"a3\", \"Angle\"]\n)][:8]\ndisplay(ref_df[key_cols].head(3))"
  },
  {
   "cell_type": "markdown",
   "id": "kn-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Kn Calibration Coefficients\n",
    "\n",
    "The Kn coefficients encode the coil sensitivity for each harmonic order.\n",
    "They depend on:\n",
    "- Coil geometry (radius, turns, winding pattern)\n",
    "- Compensation scheme (which coils are combined for ABS vs CMP channels)\n",
    "\n",
    "**Important**: Use the Kn file that matches the compensation scheme in your measurement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-kn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load kn coefficients\n",
    "kn = load_segment_kn_txt(kn_file)\n",
    "\n",
    "print(f\"Kn loaded from: {kn_file.name}\")\n",
    "print(f\"  Harmonic orders: {list(kn.orders)}\")\n",
    "print(f\"  Number of harmonics: {len(kn.orders)}\")\n",
    "\n",
    "# Display kn magnitudes\n",
    "print(\"\\nKn coefficient magnitudes:\")\n",
    "print(f\"{'n':>3} {'|kn_abs|':>15} {'|kn_cmp|':>15} {'cmp/abs':>10}\")\n",
    "print(\"-\" * 48)\n",
    "for i, n in enumerate(kn.orders):\n",
    "    abs_mag = np.abs(kn.kn_abs[i])\n",
    "    cmp_mag = np.abs(kn.kn_cmp[i])\n",
    "    ratio = cmp_mag / abs_mag if abs_mag > 1e-30 else np.nan\n",
    "    print(f\"{n:3d} {abs_mag:15.6e} {cmp_mag:15.6e} {ratio:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raw-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Parse Raw BTP8 Flux Data\n",
    "\n",
    "### BTP8 File Format\n",
    "\n",
    "The BTP8 flux files have 4 columns:\n",
    "- Column 0: `df_abs` - Incremental flux from absolute channel (Wb)\n",
    "- Column 1: `encoder` - Encoder position (counts)\n",
    "- Column 2: `df_cmp` - Incremental flux from compensated channel (Wb)\n",
    "- Column 3: `encoder` - Encoder position (duplicate)\n",
    "\n",
    "Each row represents one sample (one angular position within a turn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-parsers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_btp8_flux_file(flux_path: Path) -> tuple:\n",
    "    \"\"\"Parse BTP8 flux file (4-column format).\n",
    "    \n",
    "    Returns:\n",
    "        df_abs: Incremental flux, absolute channel (Wb)\n",
    "        df_cmp: Incremental flux, compensated channel (Wb)\n",
    "        encoder: Encoder counts (for timing)\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(flux_path)\n",
    "    df_abs = data[:, 0]\n",
    "    encoder = data[:, 1]\n",
    "    df_cmp = data[:, 2]\n",
    "    return df_abs, df_cmp, encoder\n",
    "\n",
    "\n",
    "def parse_btp8_current_file(current_path: Path) -> np.ndarray:\n",
    "    \"\"\"Parse BTP8 current file (single column).\"\"\"\n",
    "    return np.loadtxt(current_path)\n",
    "\n",
    "\n",
    "def encoder_to_time(encoder: np.ndarray, shaft_rpm: float, \n",
    "                    encoder_res: int = 40000) -> np.ndarray:\n",
    "    \"\"\"Convert encoder counts to time in seconds.\n",
    "    \n",
    "    Args:\n",
    "        encoder: Encoder counts array\n",
    "        shaft_rpm: Rotation speed in RPM\n",
    "        encoder_res: Encoder resolution (counts per revolution)\n",
    "    \"\"\"\n",
    "    counts_per_second = shaft_rpm * encoder_res / 60.0\n",
    "    return encoder / counts_per_second\n",
    "\n",
    "\n",
    "print(\"Parser functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "find-raw-files",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all raw data files\n",
    "flux_files = sorted(dataset_folder.glob(\"*_fluxes_Ascii.txt\"))\n",
    "current_files = sorted(dataset_folder.glob(\"*_current.txt\"))\n",
    "\n",
    "print(f\"Found {len(flux_files)} flux files and {len(current_files)} current files\")\n",
    "\n",
    "if len(flux_files) == 0:\n",
    "    raise FileNotFoundError(\"No flux files found in dataset folder\")\n",
    "\n",
    "# Show first few files\n",
    "print(\"\\nFirst 5 flux files:\")\n",
    "for f in flux_files[:5]:\n",
    "    print(f\"  {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inspect-first-file",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first file to understand the data structure\n",
    "test_flux_path = flux_files[0]\n",
    "test_current_path = current_files[0]\n",
    "\n",
    "df_abs, df_cmp, encoder = parse_btp8_flux_file(test_flux_path)\n",
    "current = parse_btp8_current_file(test_current_path)\n",
    "time = encoder_to_time(encoder, SHAFT_SPEED_RPM)\n",
    "\n",
    "print(f\"File: {test_flux_path.name}\")\n",
    "print(f\"  Total samples: {len(df_abs)}\")\n",
    "print(f\"  Samples per turn: {SAMPLES_PER_TURN}\")\n",
    "print(f\"  Complete turns: {len(df_abs) // SAMPLES_PER_TURN}\")\n",
    "print(f\"\\nFlux ranges:\")\n",
    "print(f\"  df_abs: [{df_abs.min():.6e}, {df_abs.max():.6e}] Wb\")\n",
    "print(f\"  df_cmp: [{df_cmp.min():.6e}, {df_cmp.max():.6e}] Wb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "process-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Process Data and Compute Harmonics\n",
    "\n",
    "### Processing Pipeline Steps\n",
    "\n",
    "1. **Parse** raw flux and current files\n",
    "2. **Reshape** samples into turns (using SAMPLES_PER_TURN)\n",
    "3. **Drift correction** (if enabled): Remove linear drift from integrated flux\n",
    "4. **FFT**: Compute Fourier coefficients from flux\n",
    "5. **Kn application**: Scale by coil sensitivity\n",
    "6. **Rotation** (if enabled): Align phase to main field\n",
    "7. **Merge**: Combine ABS and CMP channels appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_btp8_run(flux_path: Path, current_path: Path, kn,\n",
    "                     samples_per_turn: int,\n",
    "                     shaft_rpm: float,\n",
    "                     magnet_order: int,\n",
    "                     r_ref_m: float,\n",
    "                     options: tuple):\n",
    "    \"\"\"Process a single BTP8 measurement run.\n",
    "    \n",
    "    This implements the same pipeline as the legacy C++ analyzer.\n",
    "    \n",
    "    Args:\n",
    "        flux_path: Path to flux file\n",
    "        current_path: Path to current file\n",
    "        kn: SegmentKn calibration object\n",
    "        samples_per_turn: Number of samples per revolution\n",
    "        shaft_rpm: Rotation speed\n",
    "        magnet_order: Main field order (m)\n",
    "        r_ref_m: Reference radius for multipole normalization\n",
    "        options: Tuple of enabled options (\"dri\", \"rot\", etc.)\n",
    "    \n",
    "    Returns:\n",
    "        result: KnPerTurnResult with computed harmonics\n",
    "        n_turns: Number of complete turns processed\n",
    "    \"\"\"\n",
    "    # Parse files\n",
    "    df_abs, df_cmp, encoder = parse_btp8_flux_file(flux_path)\n",
    "    current = parse_btp8_current_file(current_path)\n",
    "    time = encoder_to_time(encoder, shaft_rpm)\n",
    "    \n",
    "    # Align current to flux length (they may differ slightly)\n",
    "    n_flux = len(df_abs)\n",
    "    n_curr = len(current)\n",
    "    if n_curr != n_flux:\n",
    "        indices = np.linspace(0, n_curr - 1, n_flux).astype(int)\n",
    "        current_aligned = current[indices]\n",
    "    else:\n",
    "        current_aligned = current\n",
    "    \n",
    "    # Truncate to complete turns only\n",
    "    n_turns = n_flux // samples_per_turn\n",
    "    n_samples = n_turns * samples_per_turn\n",
    "    \n",
    "    # Reshape into (n_turns, samples_per_turn)\n",
    "    df_abs_turns = df_abs[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    df_cmp_turns = df_cmp[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    t_turns = time[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    I_turns = current_aligned[:n_samples].reshape(n_turns, samples_per_turn)\n",
    "    \n",
    "    # Run the pipeline (this is the core computation)\n",
    "    result = compute_legacy_kn_per_turn(\n",
    "        df_abs_turns=df_abs_turns,\n",
    "        df_cmp_turns=df_cmp_turns,\n",
    "        t_turns=t_turns,\n",
    "        I_turns=I_turns,\n",
    "        kn=kn,\n",
    "        Rref_m=r_ref_m,\n",
    "        magnet_order=magnet_order,\n",
    "        absCalib=1.0,\n",
    "        options=options,\n",
    "    )\n",
    "    \n",
    "    return result, n_turns\n",
    "\n",
    "\n",
    "print(\"Processing function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "process-all-runs",
   "metadata": {},
   "outputs": [],
   "source": "# Process all runs and collect results\n# NOTE: Flux files contain ~14 turns each but the legacy software only uses\n# MEAS_TURNS_PER_RUN (6). We compute all turns and use greedy alignment later.\nprint(f\"Processing {len(flux_files)} measurement runs...\")\nprint(f\"Options: {OPTIONS}\")\nprint(f\"Samples per turn: {SAMPLES_PER_TURN}\")\nprint()\n\nall_results = []\ntotal_turns = 0\n\nfor i, (flux_path, current_path) in enumerate(zip(flux_files, current_files)):\n    result, n_turns = process_btp8_run(\n        flux_path=flux_path,\n        current_path=current_path,\n        kn=kn,\n        samples_per_turn=SAMPLES_PER_TURN,\n        shaft_rpm=SHAFT_SPEED_RPM,\n        magnet_order=MAGNET_ORDER,\n        r_ref_m=R_REF_M,\n        options=OPTIONS,\n    )\n    all_results.append(result)\n    total_turns += n_turns\n    \n    if (i + 1) % 10 == 0:\n        print(f\"  Processed {i + 1}/{len(flux_files)} runs...\")\n\nprint(f\"\\nDone! Processed {total_turns} total turns from {len(flux_files)} runs.\")\nprint(f\"Reference has {len(ref_df)} turns.\")\nprint(f\"(Expected: ~{MEAS_TURNS_PER_RUN} turns/run x {len(flux_files)} runs = ~{MEAS_TURNS_PER_RUN * len(flux_files)})\")"
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Compare with Reference\n",
    "\n",
    "Now we compare our computed harmonics with the golden reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-comparison-df",
   "metadata": {},
   "outputs": [],
   "source": "# Build a DataFrame with all computed harmonics (in Tesla, not normalised)\n# Then align turns with the reference using greedy matching on B2.\nrows = []\nturn_idx = 0\n\nfor result in all_results:\n    C_merged, _ = merge_coefficients(\n        C_abs=result.C_abs,\n        C_cmp=result.C_cmp,\n        magnet_order=MAGNET_ORDER,\n        mode=\"abs_upto_m_cmp_above\",\n    )\n    \n    for t in range(C_merged.shape[0]):\n        Cm = C_merged[t, MAGNET_ORDER - 1]\n        Bm = Cm.real  # Main field in Tesla (real part after rotation)\n\n        row = {\"turn_idx\": turn_idx}\n        for i, n in enumerate(result.orders):\n            C = C_merged[t, i]\n            if n <= MAGNET_ORDER:\n                # Store in Tesla for direct comparison with reference B_n (T)\n                row[f\"B{n}_T\"] = C.real\n                row[f\"A{n}_T\"] = C.imag\n            else:\n                # Normalise: units = C_n / B_main * 10000\n                if abs(Bm) > 1e-30:\n                    row[f\"b{n}_units\"] = C.real / Bm * 10000.0\n                    row[f\"a{n}_units\"] = C.imag / Bm * 10000.0\n                else:\n                    row[f\"b{n}_units\"] = np.nan\n                    row[f\"a{n}_units\"] = np.nan\n        rows.append(row)\n        turn_idx += 1\n\ncomputed_df = pd.DataFrame(rows)\nprint(f\"Computed results: {len(computed_df)} turns (all turns from all runs)\")\n\n# ── Greedy alignment: match each ref turn to its closest computed turn ──\n# The flux files contain more turns than the reference; we find the matching\n# subset by comparing the main field B2 values.\nref_b2 = ref_df[\"B2 (T)\"].values.astype(float)\ncomp_b2 = computed_df[\"B2_T\"].values\n\naligned_indices = []\nused = set()\n\nfor ri in range(len(ref_b2)):\n    best_ci = -1\n    best_diff = 1e30\n    for ci in range(len(comp_b2)):\n        if ci in used:\n            continue\n        d = abs(comp_b2[ci] - ref_b2[ri])\n        if d < best_diff:\n            best_diff = d\n            best_ci = ci\n    rel = best_diff / max(abs(ref_b2[ri]), 1e-30)\n    if rel < 1e-6:  # accept matches better than 1 ppm\n        aligned_indices.append(best_ci)\n        used.add(best_ci)\n\naligned_df = computed_df.iloc[aligned_indices].reset_index(drop=True)\nprint(f\"Aligned turns: {len(aligned_df)} / {len(ref_df)} reference turns matched\")\nif len(aligned_df) < len(ref_df):\n    print(f\"  WARNING: {len(ref_df) - len(aligned_df)} reference turns could not be matched!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-harmonics",
   "metadata": {},
   "outputs": [],
   "source": "# Compare harmonics using aligned turns\nn_compare = len(aligned_df)\nprint(f\"Comparing {n_compare} aligned turns...\\n\")\n\ndef _find_ref_col(n, component=\"B\"):\n    \"\"\"Find the reference column for harmonic n, normal (B/b) or skew (A/a).\"\"\"\n    for pattern in [\n        f\"{component}{n} (T)\",   f\"{component}{n}(T)\",\n        f\"{component.lower()}{n} (units)\", f\"{component.lower()}{n}(units)\",\n        f\"{component}{n} (units)\", f\"{component}{n}(units)\",\n        f\"{component}{n}\",\n    ]:\n        if pattern in ref_df.columns:\n            return pattern\n    return None\n\nprint(\"=\" * 98)\nprint(\"HARMONIC COMPARISON SUMMARY\")\nprint(\"=\" * 98)\nprint(f\"{'n':>3} {'Ref col':>20} {'Comp col':>16} {'Max |Diff|':>14} {'Max |Rel|':>14} {'RMS':>14} {'Status':>12}\")\nprint(\"-\" * 98)\n\ncomparison_results = []\n\nfor n in range(1, 16):\n    ref_col = _find_ref_col(n, \"B\")\n    if ref_col is None:\n        continue\n\n    # Pick the matching computed column based on format\n    if n <= MAGNET_ORDER:\n        comp_col = f\"B{n}_T\"     # Tesla\n    else:\n        comp_col = f\"b{n}_units\" # normalised\n\n    if comp_col not in aligned_df.columns:\n        continue\n\n    comp_vals = aligned_df[comp_col].values[:n_compare]\n    ref_vals = ref_df[ref_col].values[:n_compare].astype(float)\n\n    abs_diff = np.abs(comp_vals - ref_vals)\n    max_abs_diff = np.max(abs_diff)\n    rms_diff = np.sqrt(np.mean(abs_diff**2))\n\n    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n        rel_diff = np.where(\n            np.abs(ref_vals) > 1e-30,\n            np.abs((comp_vals - ref_vals) / ref_vals),\n            0.0,\n        )\n    max_rel_diff = float(np.nanmax(rel_diff))\n\n    if max_rel_diff < 1e-6:     status = \"EXCELLENT\"\n    elif max_rel_diff < 1e-3:   status = \"GOOD\"\n    elif max_rel_diff < 0.1:    status = \"CLOSE\"\n    elif max_rel_diff < 1.0:    status = \"MARGINAL\"\n    else:                        status = \"MISMATCH\"\n\n    print(f\"{n:3d} {ref_col:>20s} {comp_col:>16s} {max_abs_diff:14.6e} {max_rel_diff:14.6e} {rms_diff:14.6e} {status:>12}\")\n\n    comparison_results.append({\n        \"n\": n,\n        \"ref_col\": ref_col,\n        \"comp_col\": comp_col,\n        \"max_abs_diff\": max_abs_diff,\n        \"max_rel_diff\": max_rel_diff,\n        \"rms_diff\": rms_diff,\n        \"status\": status,\n    })"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-comparison",
   "metadata": {},
   "outputs": [],
   "source": "# Detailed comparison for main field (B2 for quadrupole)\nmain_n = MAGNET_ORDER\ncomp_col = f\"B{main_n}_T\"\nref_col = _find_ref_col(main_n, \"B\")\n\nif ref_col is None:\n    print(f\"Reference column for n={main_n} not found -- skipping detailed comparison.\")\nelse:\n    print(f\"\\nDetailed comparison for main field (n={main_n}), ref col = '{ref_col}':\")\n    print(f\"{'Turn':>6} {'Computed':>16} {'Reference':>16} {'Diff':>16} {'Rel Diff':>12}\")\n    print(\"-\" * 70)\n\n    for i in range(min(10, n_compare)):\n        comp_val = aligned_df[comp_col].iloc[i]\n        ref_val = float(ref_df[ref_col].iloc[i])\n        diff = comp_val - ref_val\n        rel_diff = diff / ref_val if abs(ref_val) > 1e-20 else 0\n        print(f\"{i:6d} {comp_val:16.9e} {ref_val:16.9e} {diff:16.9e} {rel_diff:12.6e}\")"
  },
  {
   "cell_type": "markdown",
   "id": "plots-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-comparison",
   "metadata": {},
   "outputs": [],
   "source": "# Plot computed vs reference for main field\nref_main_col = _find_ref_col(MAGNET_ORDER, \"B\")\n\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# B2 time series\nax = axes[0, 0]\nref_vals = ref_df[ref_main_col].values[:n_compare].astype(float)\ncomp_vals = aligned_df[f\"B{MAGNET_ORDER}_T\"].values[:n_compare]\nax.plot(ref_vals, 'b-', label='Reference', alpha=0.7)\nax.plot(comp_vals, 'r--', label='Computed', alpha=0.7)\nax.set_xlabel('Turn')\nax.set_ylabel(ref_main_col)\nax.set_title(f'Main Field (n={MAGNET_ORDER}): Time Series')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# B2 scatter (computed vs reference)\nax = axes[0, 1]\nax.scatter(ref_vals, comp_vals, alpha=0.5, s=10)\nlims = [min(ref_vals.min(), comp_vals.min()), max(ref_vals.max(), comp_vals.max())]\nax.plot(lims, lims, 'k--', label='Perfect match')\nax.set_xlabel('Reference')\nax.set_ylabel('Computed')\nax.set_title(f'B{MAGNET_ORDER}: Computed vs Reference')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Difference histogram\nax = axes[1, 0]\ndiff = comp_vals - ref_vals\nax.hist(diff, bins=50, edgecolor='black', alpha=0.7)\nax.axvline(0, color='r', linestyle='--', label='Zero')\nax.set_xlabel('Difference (T)')\nax.set_ylabel('Count')\nax.set_title(f'B{MAGNET_ORDER}: Difference Distribution')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Relative difference by harmonic\nax = axes[1, 1]\nharmonics = [r['n'] for r in comparison_results]\nrel_diffs = [r['max_rel_diff'] for r in comparison_results]\ncolors = ['green' if d < 1e-3 else 'orange' if d < 0.1 else 'red' for d in rel_diffs]\nax.bar(harmonics, rel_diffs, color=colors, edgecolor='black')\nax.axhline(1e-3, color='g', linestyle='--', label='Good threshold')\nax.axhline(0.1, color='orange', linestyle='--', label='Close threshold')\nax.set_xlabel('Harmonic Order n')\nax.set_ylabel('Max Relative Difference')\nax.set_title('Parity Check by Harmonic')\nax.set_yscale('log')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(output_dir / 'parity_comparison.png', dpi=150)\nplt.show()\n\nprint(f\"\\nPlot saved to: {output_dir / 'parity_comparison.png'}\")"
  },
  {
   "cell_type": "markdown",
   "id": "gui-header",
   "metadata": {},
   "source": "---\n## 9. How to Replicate Using the GUI\n\n### Step 1: Launch the GUI\n\n```bash\npy -m rotating_coil_analyzer.gui.app\n```\n\n### Step 2: File Browser Tab\n\n1. Navigate to `golden_standards/golden_standard_01_LIU_BTP8/Integral/20190717_161332_LIU`\n2. Select the flux and current files\n\n### Step 3: Coil Calibration Tab\n\n1. **Load Kn File**: Select the R45_PCB_N1 A_ABCD file:\n   `COIL_PCB/Kn_R45_PCB_N1_0001_A_ABCD.txt`\n   - Absolute channel: A (single coil)\n   - Compensated channel: A-B-C+D (long integral bucking)\n\n### Step 4: Harmonic Merge Tab\n\n1. **Magnet Order**: 2 (quadrupole)\n2. **Reference Radius**: 0.059 m\n3. **Merge Mode**: \"ABS up to m, CMP above\"\n4. **Compensation Scheme**: A / A-B-C+D\n\n### Step 5: Analysis Options\n\n1. Enable **all** options: Drift (dri), Rotation (rot), Normalization (nor), Center Location (cel), Feeddown (fed)\n2. **Samples Per Turn**: 512 (BTP8 format)\n3. Run and export\n\n### Verification\n\nCompare exported CSV with the reference `BTP8_20190717_161332_results.txt`:\n- B2 (T) should match to within < 1 ppm relative error\n- Normalized harmonics b3..b6 (units) should match to ~1-3%\n- Higher-order harmonics (b7+) show larger relative errors due to feeddown amplification\n\n### Notes on Turn Alignment\n\nThe flux files contain ~14 turns per run, but the legacy software uses only 6\n(set by `Parameters.Measurement.turns`). The notebook handles this via greedy\nmatching on the main field B2. When comparing directly, ensure you are comparing\nthe same physical measurement turns."
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export-results",
   "metadata": {},
   "outputs": [],
   "source": "# Export aligned computed results\ncomputed_path = output_dir / \"computed_results_aligned.csv\"\naligned_df.to_csv(computed_path, index=False)\nprint(f\"Aligned computed results saved to: {computed_path}\")\n\n# Export comparison summary\ncomparison_df = pd.DataFrame(comparison_results)\ncomparison_path = output_dir / \"comparison_summary.csv\"\ncomparison_df.to_csv(comparison_path, index=False)\nprint(f\"Comparison summary saved to: {comparison_path}\")\n\n# Export provenance metadata\nmetadata = {\n    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n    \"dataset_folder\": str(dataset_folder),\n    \"kn_file\": str(kn_file),\n    \"magnet_order\": MAGNET_ORDER,\n    \"r_ref_m\": R_REF_M,\n    \"samples_per_turn\": SAMPLES_PER_TURN,\n    \"options\": OPTIONS,\n    \"n_computed_turns\": len(computed_df),\n    \"n_aligned_turns\": len(aligned_df),\n    \"n_reference_turns\": len(ref_df),\n}\n\nmetadata_path = output_dir / \"provenance.json\"\nwith open(metadata_path, \"w\") as f:\n    json.dump(metadata, f, indent=2)\nprint(f\"Provenance metadata saved to: {metadata_path}\")"
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-summary",
   "metadata": {},
   "outputs": [],
   "source": "# Print final summary\nprint(\"=\" * 80)\nprint(\"GOLDEN STANDARD PARITY VALIDATION - FINAL REPORT\")\nprint(\"=\" * 80)\nprint(f\"\\nGenerated: {datetime.now().isoformat()}\")\nprint(f\"\\nDataset: {dataset_folder.name}\")\nprint(f\"Kn file: {kn_file.name}\")\nprint(f\"\\nConfiguration:\")\nprint(f\"  Magnet order: {MAGNET_ORDER}\")\nprint(f\"  Reference radius: {R_REF_M} m\")\nprint(f\"  Samples per turn: {SAMPLES_PER_TURN}\")\nprint(f\"  Options: {OPTIONS}\")\n\nprint(f\"\\nData processed:\")\nprint(f\"  Computed turns: {len(computed_df)} (all turns from flux files)\")\nprint(f\"  Aligned turns: {len(aligned_df)} (matched to reference)\")\nprint(f\"  Reference turns: {len(ref_df)}\")\n\nprint(f\"\\nParity Results:\")\nexcellent = sum(1 for r in comparison_results if r['status'] == 'EXCELLENT')\ngood = sum(1 for r in comparison_results if r['status'] == 'GOOD')\nclose = sum(1 for r in comparison_results if r['status'] == 'CLOSE')\nmarginal = sum(1 for r in comparison_results if r['status'] == 'MARGINAL')\nmismatch = sum(1 for r in comparison_results if r['status'] == 'MISMATCH')\n\nprint(f\"  EXCELLENT (< 1e-6 rel): {excellent} harmonics\")\nprint(f\"  GOOD (< 1e-3 rel):      {good} harmonics\")\nprint(f\"  CLOSE (< 0.1 rel):      {close} harmonics\")\nprint(f\"  MARGINAL (< 1.0 rel):   {marginal} harmonics\")\nprint(f\"  MISMATCH (>= 1.0 rel):  {mismatch} harmonics\")\n\nif mismatch == 0 and marginal == 0:\n    print(\"\\n\" + \"*\" * 80)\n    print(\"VALIDATION PASSED: All harmonics match within acceptable tolerance!\")\n    print(\"*\" * 80)\nelif mismatch == 0:\n    print(\"\\n\" + \"*\" * 80)\n    print(\"VALIDATION MOSTLY PASSED: Main field excellent, some marginal harmonics.\")\n    print(\"*\" * 80)\nelse:\n    print(\"\\n\" + \"!\" * 80)\n    print(f\"VALIDATION PARTIAL: Main field correct, {mismatch} higher harmonics diverge.\")\n    print(\"Higher-order errors are expected due to feeddown amplification and CMP noise.\")\n    print(\"!\" * 80)\n\nprint(f\"\\nOutput files:\")\nprint(f\"  {computed_path}\")\nprint(f\"  {comparison_path}\")\nprint(f\"  {metadata_path}\")\nprint(f\"  {output_dir / 'parity_comparison.png'}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}