{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb50446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68cb5e521bfb456089fcbaad9024645e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='', description='Folder', layout=Layout(width='80%'), placeholder='..…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ipywidgets as w\n",
    "w.Widget.close_all()\n",
    "\n",
    "from rotating_coil_analyzer.gui.app import build_catalog_gui\n",
    "gui = build_catalog_gui()\n",
    "gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec2353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from rotating_coil_analyzer.ingest.readers_sm18 import Sm18CorrSigsReader\n",
    "\n",
    "# 1) Point to the exact file you are debugging (example: Seg3)\n",
    "fpath = r\"C:\\Local data\\2025_12_SM18test\\HCMCBRD_S001-CR000012_20240315_093813_AP1-0_AP2-Stair_Step\\aperture1\\HCMCBRD_S001-CR000012_20240315_093813_AP1-0_AP2-Stair_Step_corr_sigs_Ap_1_Seg3.bin\"\n",
    "\n",
    "# 2) Run id (usually the prefix of your file/folder; keep consistent)\n",
    "run_id = \"HCMCBRD_S001-CR000012_20240315_093813_AP1-0_AP2-Stair_Step\"\n",
    "\n",
    "# 3) Segment from filename (fallback to \"3\" if parsing fails)\n",
    "m = re.search(r\"_Seg(\\d+)\\.bin$\", os.path.basename(fpath))\n",
    "segment = m.group(1) if m else \"3\"\n",
    "\n",
    "# 4) Acquisition settings (from Parameters.txt)\n",
    "Ns = 512\n",
    "shaft_speed_rpm = 60.0  # use abs(v); sign doesn't matter for period\n",
    "\n",
    "reader = Sm18CorrSigsReader()\n",
    "seg_frame = reader.read(\n",
    "    fpath,\n",
    "    run_id=run_id,\n",
    "    segment=segment,\n",
    "    samples_per_turn=Ns,\n",
    "    shaft_speed_rpm=shaft_speed_rpm,\n",
    ")\n",
    "\n",
    "seg_frame, seg_frame.df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5314a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = seg_frame.df\n",
    "Ns = seg_frame.samples_per_turn\n",
    "n_turns = len(df) // Ns\n",
    "sl = slice(0, n_turns*Ns)\n",
    "\n",
    "abs_mat = df[\"df_abs\"].to_numpy()[sl].reshape(n_turns, Ns)\n",
    "abs_rms = np.sqrt(np.mean(abs_mat**2, axis=1))  # per-turn amplitude proxy\n",
    "\n",
    "cand = [c for c in [\"I\", \"I0\", \"I1\", \"I2\"] if c in df.columns]\n",
    "print(\"candidates:\", cand)\n",
    "\n",
    "for c in cand:\n",
    "    x = df[c].to_numpy()[sl].reshape(n_turns, Ns)\n",
    "    per_turn_med = np.median(x, axis=1)\n",
    "    within_turn_std_med = float(np.median(np.std(x, axis=1)))\n",
    "\n",
    "    corr = np.corrcoef(per_turn_med, abs_rms)[0, 1]\n",
    "    p05, p995 = np.percentile(per_turn_med, [0.5, 99.5])\n",
    "\n",
    "    print(f\"{c:>3s}  within-turn std~{within_turn_std_med:.4g}   \"\n",
    "          f\"turn-med range(p99.5-p0.5)~{(p995-p05):.4g}   corr(abs_rms)={corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sl = slice(0, (len(seg_frame.df)//seg_frame.samples_per_turn)*seg_frame.samples_per_turn)\n",
    "for c in [\"I\", \"I1\", \"I2\"]:\n",
    "    if c in seg_frame.df.columns:\n",
    "        print(c, float(np.nanmax(np.abs(seg_frame.df[c].to_numpy()[sl] - seg_frame.df[\"I\"].to_numpy()[sl]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda30b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = seg_frame.df\n",
    "Ns = seg_frame.samples_per_turn\n",
    "n_turns = len(df)//Ns\n",
    "\n",
    "t_turn = df[\"t\"].to_numpy()[0:n_turns*Ns:Ns]  # one timestamp per turn\n",
    "for c in [\"I0\",\"I1\",\"I2\",\"I\"]:\n",
    "    if c in df.columns:\n",
    "        x = df[c].to_numpy()[:n_turns*Ns].reshape(n_turns, Ns)\n",
    "        plt.figure()\n",
    "        plt.plot(t_turn, np.median(x, axis=1))\n",
    "        plt.title(f\"per-turn median of {c}\")\n",
    "        plt.xlabel(\"t_turn [s]\")\n",
    "        plt.ylabel(c)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594dbacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = seg_frame.df\n",
    "\n",
    "# Sample-level correlation (often strong magnitude)\n",
    "corr = np.corrcoef(df[\"df_abs\"].to_numpy(), df[\"df_cmp\"].to_numpy())[0,1]\n",
    "print(\"corr(df_abs, df_cmp) =\", corr)\n",
    "\n",
    "# RMS ratio (cmp should be much smaller than abs)\n",
    "rms_abs = np.sqrt(np.mean(df[\"df_abs\"].to_numpy()**2))\n",
    "rms_cmp = np.sqrt(np.mean(df[\"df_cmp\"].to_numpy()**2))\n",
    "print(\"rms_cmp/rms_abs =\", rms_cmp/rms_abs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "I1 = df[\"I1\"].to_numpy()\n",
    "I2 = df[\"I2\"].to_numpy()\n",
    "\n",
    "print(\"corr(I1, I2) =\", np.corrcoef(I1, I2)[0,1])\n",
    "print(\"max|I1-I2| =\", np.max(np.abs(I1 - I2)))\n",
    "print(\"std(I1-I2) =\", np.std(I1 - I2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f7903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c6cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea41e124",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e136cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ROOT === C:\\Local data\\2025_12_19-analyzer_tests\\867_Alberto\\20251212_171026_SPS_MBA\\20251212_171620_MBA\n",
      "runs: ('20251212_171620_MBA',)\n",
      "aps: [None]\n",
      "segments: [(1, 'NCS'), (1, 'CS')]\n",
      "OK: 20251212_171620_MBA_Run_00_I_0.00A_NCS_raw_measurement_data.txt | n_turns: 3502 | Ns: 1024 | n_samples: 3586048\n",
      "  warnings:\n",
      "   - MBA reader: concatenating 125 plateau files for base='20251212_171620_MBA', segment='NCS'\n",
      "   - large concatenated MBA trace: 3586048 rows (preview/plotting may be slow).\n",
      "   - current candidate ranges (p99.5-p0.5): col3:3105.8, col4:0.48658\n",
      "   - selected main current column: col3 (stored as df['I'])\n",
      "WARNING: non-monotonic t within plateau_id=66 in 20251212_171620_MBA_Run_00_I_0.00A_CS_raw_measurement_data.txt\n",
      "OK: 20251212_171620_MBA_Run_00_I_0.00A_CS_raw_measurement_data.txt | n_turns: 3502 | Ns: 1024 | n_samples: 3586048\n",
      "  warnings:\n",
      "   - MBA reader: concatenating 125 plateau files for base='20251212_171620_MBA', segment='CS'\n",
      "   - large concatenated MBA trace: 3586048 rows (preview/plotting may be slow).\n",
      "   - current candidate ranges (p99.5-p0.5): col3:3105.8, col4:0.48658\n",
      "   - selected main current column: col3 (stored as df['I'])\n",
      "\n",
      "Layer C smoke run completed.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from rotating_coil_analyzer.ingest.discovery import MeasurementDiscovery\n",
    "from rotating_coil_analyzer.ingest.readers_sm18 import Sm18CorrSigsReader, Sm18ReaderConfig\n",
    "from rotating_coil_analyzer.ingest.readers_mba import MbaRawMeasurementReader, MbaReaderConfig\n",
    "\n",
    "ROOTS = [\n",
    "    Path(r\"C:/Local data/2025_12_19-analyzer_tests/867_Alberto/20251212_171026_SPS_MBA/20251212_171620_MBA\"),\n",
    "    # Path(r\"PASTE_PATH_TO_A_REAL_DATASET_FOLDER_2\"),\n",
    "]\n",
    "\n",
    "def check_segment(cat, run_id, ap_ui, seg_id):\n",
    "    f = cat.get_segment_file(run_id, ap_ui, seg_id)\n",
    "    ap_phys = cat.resolve_aperture(ap_ui)\n",
    "\n",
    "    if f.name.lower().endswith(\"_raw_measurement_data.txt\"):\n",
    "        segf = MbaRawMeasurementReader(MbaReaderConfig()).read(\n",
    "            f, run_id=run_id, segment=str(seg_id),\n",
    "            samples_per_turn=cat.samples_per_turn, aperture_id=ap_phys\n",
    "        )\n",
    "\n",
    "        # MBA: No synthetic time. Raw 't' may reset across plateaus; check plateau-safe turns.\n",
    "        assert \"plateau_id\" in segf.df.columns, \"MBA must provide plateau_id\"\n",
    "        Ns = segf.samples_per_turn\n",
    "        pid = segf.df[\"plateau_id\"].to_numpy()\n",
    "        jumps = np.where(np.diff(pid) != 0)[0]\n",
    "        for j in jumps:\n",
    "            assert ((j + 1) % Ns) == 0, f\"Plateau boundary not aligned to turn boundary at sample {j+1}\"\n",
    "\n",
    "        # Optional diagnostic: within each plateau, time should be non-decreasing (warn-level check here)\n",
    "        t = segf.df[\"t\"].to_numpy()\n",
    "        for p in np.unique(pid):\n",
    "            mask = (pid == p)\n",
    "            tt = t[mask]\n",
    "            dt = np.diff(tt)\n",
    "            if not (np.all(np.isfinite(dt)) and np.all(dt >= 0)):\n",
    "                print(f\"WARNING: non-monotonic t within plateau_id={int(p)} in {f.name}\")\n",
    "\n",
    "    else:\n",
    "        segf = Sm18CorrSigsReader(Sm18ReaderConfig(strict_time=True)).read(\n",
    "            f, run_id=run_id, segment=str(seg_id),\n",
    "            samples_per_turn=cat.samples_per_turn, shaft_speed_rpm=cat.shaft_speed_rpm,\n",
    "            aperture_id=ap_phys\n",
    "        )\n",
    "\n",
    "        # SM18: 't' is raw file time; strict_time=True requires strictly increasing.\n",
    "        t = segf.df[\"t\"].to_numpy()\n",
    "        dt = np.diff(t)\n",
    "        assert np.all(np.isfinite(dt)) and np.all(dt > 0), \"SM18 time must be strictly increasing\"\n",
    "\n",
    "    # Common invariants\n",
    "    assert len(segf.df) == segf.n_turns * segf.samples_per_turn\n",
    "    for col in [\"t\", \"df_abs\", \"df_cmp\", \"I\"]:\n",
    "        assert col in segf.df.columns, f\"Missing required column {col}\"\n",
    "\n",
    "    return f, segf\n",
    "\n",
    "for root in ROOTS:\n",
    "    print(\"\\n=== ROOT ===\", root)\n",
    "    cat = MeasurementDiscovery(strict=True).build_catalog(root)\n",
    "    print(\"runs:\", cat.runs)\n",
    "    print(\"aps:\", cat.logical_apertures)\n",
    "    print(\"segments:\", [(s.aperture_id, s.segment_id) for s in cat.segments])\n",
    "\n",
    "    # Check up to a few segments (so it’s not too slow)\n",
    "    n_checked = 0\n",
    "    for run_id in cat.runs[:3]:\n",
    "        for ap_ui in cat.logical_apertures[:2]:\n",
    "            segs = cat.segments_for_aperture(ap_ui)\n",
    "            for s in segs[:3]:\n",
    "                f, segf = check_segment(cat, run_id, ap_ui, s.segment_id)\n",
    "                print(\"OK:\", f.name, \"| n_turns:\", segf.n_turns, \"| Ns:\", segf.samples_per_turn, \"| n_samples:\", len(segf.df))\n",
    "                if segf.warnings:\n",
    "                    print(\"  warnings:\")\n",
    "                    for w in segf.warnings[:12]:\n",
    "                        print(\"   -\", w)\n",
    "                    if len(segf.warnings) > 12:\n",
    "                        print(f\"   - ... ({len(segf.warnings)-12} more)\")\n",
    "                n_checked += 1\n",
    "                if n_checked >= 10:\n",
    "                    break\n",
    "            if n_checked >= 10:\n",
    "                break\n",
    "        if n_checked >= 10:\n",
    "            break\n",
    "\n",
    "print(\"\\nLayer C smoke run completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96b61e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plateau_id: 66\n",
      "plateau_step: 66\n",
      "plateau_I_hint: 2900.0\n",
      "n_samples: 28672\n",
      "t finite: 27648 / 28672\n",
      "dt finite: 27647 / 28671\n",
      "min dt (finite): 0.0009360000003653113\n",
      "n dt < 0: 0\n",
      "n non-finite dt: 1024\n",
      "first bad indices: [27647 27648 27649 27650 27651 27652 27653 27654 27655 27656 27657 27658\n",
      " 27659 27660 27661 27662 27663 27664 27665 27666]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "pid = 66\n",
    "sub = segf.df[segf.df[\"plateau_id\"] == pid]\n",
    "t = sub[\"t\"].to_numpy()\n",
    "\n",
    "dt = np.diff(t)\n",
    "print(\"plateau_id:\", pid)\n",
    "print(\"plateau_step:\", int(sub[\"plateau_step\"].iloc[0]))\n",
    "print(\"plateau_I_hint:\", float(sub[\"plateau_I_hint\"].iloc[0]))\n",
    "print(\"n_samples:\", len(sub))\n",
    "print(\"t finite:\", np.sum(np.isfinite(t)), \"/\", len(t))\n",
    "print(\"dt finite:\", np.sum(np.isfinite(dt)), \"/\", len(dt))\n",
    "print(\"min dt (finite):\", np.min(dt[np.isfinite(dt)]))\n",
    "print(\"n dt < 0:\", np.sum((dt[np.isfinite(dt)]) < 0))\n",
    "print(\"n non-finite dt:\", np.sum(~np.isfinite(dt)))\n",
    "\n",
    "# Where does it happen?\n",
    "bad = np.where((~np.isfinite(dt)) | (dt < 0))[0]\n",
    "print(\"first bad indices:\", bad[:20])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
