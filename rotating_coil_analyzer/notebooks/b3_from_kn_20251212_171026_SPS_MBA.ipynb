{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b3 from Kn + raw data -- SPS MBA\n",
    "\n",
    "**Measurement session:** `20251212_171026_SPS_MBA`  \n",
    "**Magnet:** MBA (dipole, normal)  \n",
    "**Project:** SPS  \n",
    "\n",
    "This notebook **bypasses the GUI** and computes field harmonics directly\n",
    "from the Kn calibration files and per-run raw measurement data.\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "Replace the all-zero Kn files with the correct calibration constants:\n",
    "\n",
    "```\n",
    "measurements/20251212_171026_SPS_MBA/Kn_values_Seg_CS.txt\n",
    "measurements/20251212_171026_SPS_MBA/Kn_values_Seg_NCS.txt\n",
    "```\n",
    "\n",
    "Each file: 15 rows (harmonics n=1..15) x 4 columns  \n",
    "`AbsRe  AbsIm  CmpRe  CmpIm`  (complex Kn for absolute and compensated channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({\n",
    "    \"figure.figsize\": (10, 5),\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.alpha\": 0.3,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration (from Parameters.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "SESSION = \"20251212_171026_SPS_MBA\"\nMEAS_SUBDIR = \"20251212_171620_MBA\"\n\n# Repo root -- walk up from CWD until we find pyproject.toml or .git\nREPO_ROOT = Path(\".\").resolve()\nwhile REPO_ROOT != REPO_ROOT.parent:\n    if (REPO_ROOT / \"pyproject.toml\").exists() or (REPO_ROOT / \".git\").exists():\n        break\n    REPO_ROOT = REPO_ROOT.parent\n\nSESSION_DIR = REPO_ROOT / \"measurements\" / SESSION\nRUN_DIR = SESSION_DIR / MEAS_SUBDIR\n\n# Magnet / measurement parameters (from Parameters.txt)\nR_REF = 0.02            # reference radius [m]\nL_COIL = 0.47           # shaft / coil length [m]\nSAMPLES_PER_TURN = 1024 # encoder pulses per revolution\nMAGNET_ORDER = 1        # dipole\n\nprint(f\"Repo root   : {REPO_ROOT}\")\nprint(f\"Session dir : {SESSION_DIR}\")\nprint(f\"Run dir     : {RUN_DIR}\")\nprint(f\"R_ref       : {R_REF} m\")\nprint(f\"Samples/turn: {SAMPLES_PER_TURN}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and validate Kn files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kn(path: Path):\n",
    "    \"\"\"Load a Kn file (15 x 4) and return complex arrays kn_abs, kn_cmp.\"\"\"\n",
    "    arr = np.loadtxt(path)  # (15, 4): AbsRe AbsIm CmpRe CmpIm\n",
    "    kn_abs = arr[:, 0] + 1j * arr[:, 1]\n",
    "    kn_cmp = arr[:, 2] + 1j * arr[:, 3]\n",
    "    return kn_abs, kn_cmp\n",
    "\n",
    "\n",
    "kn_cs_path = SESSION_DIR / \"Kn_values_Seg_CS.txt\"\n",
    "kn_ncs_path = SESSION_DIR / \"Kn_values_Seg_NCS.txt\"\n",
    "\n",
    "kn_abs_cs, kn_cmp_cs = load_kn(kn_cs_path)\n",
    "kn_abs_ncs, kn_cmp_ncs = load_kn(kn_ncs_path)\n",
    "\n",
    "# Validate: all-zero Kn will produce garbage\n",
    "for name, kn in [(\"CS abs\", kn_abs_cs), (\"CS cmp\", kn_cmp_cs),\n",
    "                  (\"NCS abs\", kn_abs_ncs), (\"NCS cmp\", kn_cmp_ncs)]:\n",
    "    if np.all(kn == 0):\n",
    "        warnings.warn(f\"{name} Kn is ALL ZEROS -- replace the file before running!\",\n",
    "                       stacklevel=1)\n",
    "    else:\n",
    "        print(f\"{name:>8s}: {np.count_nonzero(kn):2d}/15 non-zero, \"\n",
    "              f\"|Kn| range [{np.abs(kn[kn!=0]).min():.4e}, {np.abs(kn[kn!=0]).max():.4e}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Kn values as a table\n",
    "kn_table = pd.DataFrame({\n",
    "    \"n\": np.arange(1, 16),\n",
    "    \"CS_abs_Re\": kn_abs_cs.real,\n",
    "    \"CS_abs_Im\": kn_abs_cs.imag,\n",
    "    \"CS_cmp_Re\": kn_cmp_cs.real,\n",
    "    \"CS_cmp_Im\": kn_cmp_cs.imag,\n",
    "    \"NCS_abs_Re\": kn_abs_ncs.real,\n",
    "    \"NCS_abs_Im\": kn_abs_ncs.imag,\n",
    "    \"NCS_cmp_Re\": kn_cmp_ncs.real,\n",
    "    \"NCS_cmp_Im\": kn_cmp_ncs.imag,\n",
    "}).set_index(\"n\")\n",
    "\n",
    "print(\"Kn calibration constants (real / imaginary parts):\")\n",
    "kn_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Harmonics engine\n",
    "\n",
    "Replicates the core of `kn_pipeline.py`: FFT of integrated flux, then Kn calibration.\n",
    "\n",
    "$$\n",
    "C_n = \\frac{2\\,\\mathrm{FFT}[\\Phi]_n}{N_s}\n",
    "      \\;\\cdot\\;\n",
    "      \\frac{r_\\mathrm{ref}^{\\,n-1}}{K_n^*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_flux(df_incremental: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Cumulative-sum integration with linear-drift removal per turn.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_incremental : (n_turns, Ns) incremental flux values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    flux : (n_turns, Ns) drift-corrected integrated flux\n",
    "    \"\"\"\n",
    "    flux = np.cumsum(df_incremental, axis=1)\n",
    "    Ns = flux.shape[1]\n",
    "    # Remove linear drift so the flux is periodic\n",
    "    drift = np.linspace(0, 1, Ns)[None, :] * (flux[:, -1:] - flux[:, :1])\n",
    "    return flux - drift\n",
    "\n",
    "\n",
    "def compute_harmonics(flux: np.ndarray, kn: np.ndarray, Rref: float) -> np.ndarray:\n",
    "    \"\"\"FFT + Kn calibration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flux : (n_turns, Ns) integrated flux\n",
    "    kn   : (H,) complex calibration constants\n",
    "    Rref : reference radius [m]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    C : (n_turns, H) complex harmonic coefficients Bn + j*An\n",
    "    \"\"\"\n",
    "    Ns = flux.shape[1]\n",
    "    H = len(kn)\n",
    "\n",
    "    # Normalised FFT: keep harmonics 1..H (skip DC at index 0)\n",
    "    f = (2.0 * np.fft.fft(flux, axis=1)) / float(Ns)\n",
    "    f = f[:, 1:H + 1]  # (n_turns, H)\n",
    "\n",
    "    # Sensitivity: sens_n = Rref^(n-1) / conj(kn_n)\n",
    "    idx = np.arange(H, dtype=float)  # 0, 1, ..., H-1 = n-1 for n=1..H\n",
    "    sens = (Rref ** idx) / np.conj(kn)\n",
    "\n",
    "    return f * sens[None, :]  # broadcast (n_turns, H)\n",
    "\n",
    "\n",
    "print(\"Engine ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discover per-run raw-measurement files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_run_files(run_dir: Path):\n",
    "    \"\"\"Return sorted list of (run_index, current_A, segment, path).\"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"Run_(\\d+)_I_([\\d.]+)A_(N?CS)_raw_measurement_data\\.txt$\"\n",
    "    )\n",
    "    entries = []\n",
    "    for f in sorted(run_dir.iterdir()):\n",
    "        m = pattern.search(f.name)\n",
    "        if m:\n",
    "            entries.append((\n",
    "                int(m.group(1)),    # run index\n",
    "                float(m.group(2)),  # nominal current\n",
    "                m.group(3),         # segment: CS or NCS\n",
    "                f,                  # full path\n",
    "            ))\n",
    "    return entries\n",
    "\n",
    "\n",
    "run_files = parse_run_files(RUN_DIR)\n",
    "n_cs = sum(1 for r in run_files if r[2] == \"CS\")\n",
    "n_ncs = sum(1 for r in run_files if r[2] == \"NCS\")\n",
    "print(f\"Found {len(run_files)} raw files  (CS: {n_cs}, NCS: {n_ncs})\")\n",
    "print(f\"Current range: {min(r[1] for r in run_files):.0f} .. {max(r[1] for r in run_files):.0f} A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process all runs\n",
    "\n",
    "For each run: read raw data &#x2192; split into turns &#x2192; integrate &#x2192; FFT + Kn &#x2192; average over turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_run(path: Path, kn_abs, kn_cmp, Rref, Ns):\n",
    "    \"\"\"Return (C_abs_mean, C_cmp_mean, I_mean, time_mean, n_turns).\"\"\"\n",
    "    raw = np.loadtxt(path)  # columns: time, df_abs, df_cmp, I, ramprate\n",
    "\n",
    "    n_samples = raw.shape[0]\n",
    "    n_turns = n_samples // Ns\n",
    "    usable = n_turns * Ns  # trim incomplete last turn\n",
    "\n",
    "    time_arr = raw[:usable, 0].reshape(n_turns, Ns)\n",
    "    df_abs   = raw[:usable, 1].reshape(n_turns, Ns)\n",
    "    df_cmp   = raw[:usable, 2].reshape(n_turns, Ns)\n",
    "    I_arr    = raw[:usable, 3].reshape(n_turns, Ns)\n",
    "\n",
    "    flux_abs = integrate_flux(df_abs)\n",
    "    flux_cmp = integrate_flux(df_cmp)\n",
    "\n",
    "    C_abs = compute_harmonics(flux_abs, kn_abs, Rref)\n",
    "    C_cmp = compute_harmonics(flux_cmp, kn_cmp, Rref)\n",
    "\n",
    "    return (\n",
    "        C_abs.mean(axis=0),   # (H,) complex\n",
    "        C_cmp.mean(axis=0),\n",
    "        I_arr.mean(),         # scalar\n",
    "        time_arr.mean(),\n",
    "        n_turns,\n",
    "    )\n",
    "\n",
    "\n",
    "# --- main processing loop ---\n",
    "records = []\n",
    "kn_map = {\n",
    "    \"CS\":  (kn_abs_cs, kn_cmp_cs),\n",
    "    \"NCS\": (kn_abs_ncs, kn_cmp_ncs),\n",
    "}\n",
    "\n",
    "any_kn_zero = any(np.all(k == 0) for k in [kn_abs_cs, kn_cmp_cs, kn_abs_ncs, kn_cmp_ncs])\n",
    "if any_kn_zero:\n",
    "    print(\"WARNING: At least one Kn array is all zeros.\")\n",
    "    print(\"Replace the Kn files and re-run this cell.\")\n",
    "    print(\"Skipping computation.\")\n",
    "else:\n",
    "    for run_idx, I_nom, seg, path in run_files:\n",
    "        kn_a, kn_c = kn_map[seg]\n",
    "        try:\n",
    "            C_abs, C_cmp, I_mean, t_mean, nturns = process_run(\n",
    "                path, kn_a, kn_c, R_REF, SAMPLES_PER_TURN\n",
    "            )\n",
    "            rec = {\n",
    "                \"run\": run_idx,\n",
    "                \"segment\": seg,\n",
    "                \"I_nom_A\": I_nom,\n",
    "                \"I_mean_A\": I_mean,\n",
    "                \"time_s\": t_mean,\n",
    "                \"n_turns\": nturns,\n",
    "            }\n",
    "            # Store all Bn and An (using the compensated channel, which is\n",
    "            # standard for higher harmonics; absolute for n=1)\n",
    "            H = len(C_abs)\n",
    "            for n in range(1, H + 1):\n",
    "                i = n - 1\n",
    "                C = C_abs[i] if n == MAGNET_ORDER else C_cmp[i]\n",
    "                rec[f\"B{n}\"] = C.real\n",
    "                rec[f\"A{n}\"] = C.imag\n",
    "                # Also keep absolute-channel values for reference\n",
    "                rec[f\"B{n}_abs\"] = C_abs[i].real\n",
    "                rec[f\"A{n}_abs\"] = C_abs[i].imag\n",
    "            records.append(rec)\n",
    "        except Exception as exc:\n",
    "            print(f\"  SKIP {path.name}: {exc}\")\n",
    "\n",
    "    print(f\"\\nProcessed {len(records)} runs successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not records:\n",
    "    raise RuntimeError(\n",
    "        \"No data processed.  Replace the Kn files and re-run from cell 2.\"\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.sort_values([\"segment\", \"run\"], inplace=True, ignore_index=True)\n",
    "\n",
    "print(f\"{len(df)} rows, segments: {sorted(df['segment'].unique())}\")\n",
    "df[[\"run\", \"segment\", \"I_nom_A\", \"I_mean_A\", \"time_s\", \"B1\", \"B3\", \"n_turns\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. b3 vs time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for seg in sorted(df[\"segment\"].unique()):\n",
    "    sub = df[df[\"segment\"] == seg]\n",
    "    ax.plot(sub[\"time_s\"], sub[\"B3\"], \"o-\", markersize=3, label=seg)\n",
    "\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"B3 (T)\")\n",
    "ax.set_title(f\"b3 vs time  --  {SESSION}\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. b3 vs current (scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for seg in sorted(df[\"segment\"].unique()):\n",
    "    sub = df[df[\"segment\"] == seg]\n",
    "    ax.plot(sub[\"I_mean_A\"], sub[\"B3\"], \"o\", markersize=4, label=seg)\n",
    "\n",
    "ax.set_xlabel(\"I (A)\")\n",
    "ax.set_ylabel(\"B3 (T)\")\n",
    "ax.set_title(f\"b3 vs current  --  {SESSION}\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. b3 histogram + summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for seg in sorted(df[\"segment\"].unique()):\n",
    "    vals = df.loc[df[\"segment\"] == seg, \"B3\"]\n",
    "    ax.hist(vals, bins=\"auto\", alpha=0.6, label=seg,\n",
    "            edgecolor=\"black\", linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(\"B3 (T)\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(f\"b3 histogram  --  {SESSION}\")\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "summary = (\n",
    "    df.groupby(\"segment\")[\"B3\"]\n",
    "    .agg([\"count\", \"mean\", \"std\", \"min\", \"max\"])\n",
    "    .rename(columns={\"count\": \"N\"})\n",
    ")\n",
    "print(\"\\nSummary statistics (B3, in Tesla):\")\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. b3 ramp-up vs ramp-down (hysteresis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), sharey=True)\n",
    "\n",
    "for i, seg in enumerate(sorted(df[\"segment\"].unique())):\n",
    "    ax = axes[i]\n",
    "    sub = df[df[\"segment\"] == seg].copy()\n",
    "\n",
    "    # Split by ramp direction: current first rises then falls\n",
    "    I_vals = sub[\"I_nom_A\"].values\n",
    "    peak_idx = np.argmax(I_vals)\n",
    "    up = sub.iloc[:peak_idx + 1]\n",
    "    down = sub.iloc[peak_idx:]\n",
    "\n",
    "    ax.plot(up[\"I_mean_A\"], up[\"B3\"], \"o-\", markersize=3, label=\"ramp up\")\n",
    "    ax.plot(down[\"I_mean_A\"], down[\"B3\"], \"s-\", markersize=3, label=\"ramp down\")\n",
    "    ax.set_xlabel(\"I (A)\")\n",
    "    ax.set_ylabel(\"B3 (T)\")\n",
    "    ax.set_title(seg)\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle(f\"b3 hysteresis  --  {SESSION}\", fontsize=13)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Full harmonic spectrum at peak current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_cols = [c for c in df.columns if re.match(r\"^B\\d+$\", c)]\n",
    "bn_cols = sorted(bn_cols, key=lambda c: int(c[1:]))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for i, seg in enumerate(sorted(df[\"segment\"].unique())):\n",
    "    sub = df[df[\"segment\"] == seg]\n",
    "    row = sub.loc[sub[\"I_mean_A\"].abs().idxmax()]\n",
    "    orders = [int(c[1:]) for c in bn_cols]\n",
    "    vals = [row[c] for c in bn_cols]\n",
    "\n",
    "    ax = axes[i]\n",
    "    colors = [\"tab:red\" if o == 3 else \"tab:blue\" for o in orders]\n",
    "    ax.bar(orders, vals, color=colors)\n",
    "    ax.set_xlabel(\"Harmonic order n\")\n",
    "    ax.set_ylabel(\"Bn (T)\")\n",
    "    ax.set_title(f\"{seg} at I = {row['I_mean_A']:.0f} A\")\n",
    "    ax.axhline(0, color=\"grey\", linewidth=0.5)\n",
    "\n",
    "fig.suptitle(f\"Normal harmonic spectrum  --  {SESSION}\", fontsize=13)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 11. Export computed results\n\nSave to `output/` for archival and further analysis."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "out_dir = REPO_ROOT / \"output\" / SESSION\nout_dir.mkdir(parents=True, exist_ok=True)\n\nfor seg in sorted(df[\"segment\"].unique()):\n    sub = df[df[\"segment\"] == seg]\n    fname = f\"MBA_{seg}_computed_results.csv\"\n    sub.to_csv(out_dir / fname, index=False)\n    print(f\"Wrote {out_dir / fname}  ({len(sub)} rows)\")\n\nprint(\"\\nDone.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Reproducing in the GUI\n",
    "\n",
    "- [ ] **Launch:** `py -m rotating_coil_analyzer.gui.app`\n",
    "- [ ] **Load:** `measurements/20251212_171026_SPS_MBA`\n",
    "- [ ] **Select** aperture / segment (CS, NCS, or both)\n",
    "- [ ] **Set** magnet order = 1 (dipole), reference radius r_ref = 0.02 m\n",
    "- [ ] **Ensure** the correct Kn files are in place (non-zero!)\n",
    "- [ ] **Run** harmonics analysis\n",
    "- [ ] **Export** results to `output/`\n",
    "- [ ] **Compare** with the CSV exported by cell 11 above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What to check if GUI and notebook disagree\n",
    "\n",
    "| Symptom | Likely cause | Fix |\n",
    "|---------|-------------|-----|\n",
    "| b3 values differ slightly | Turn averaging or drift correction differs | Compare n_turns used; check GUI drift-correction setting |\n",
    "| Sign flip on b3 | Different sign convention or rotation angle | Check whether the GUI applies rotation (\"rot\" option) |\n",
    "| Amplitude scale differs | Different R_ref | Verify both use R_ref = 0.02 m |\n",
    "| Spectrum shape differs | Notebook uses cmp for n>1, abs for n=1 | GUI may use a different merge strategy |\n",
    "| Abs vs Cmp channel swap | Column order in raw file differs | Try swapping columns 1 and 2 in `process_run` |\n",
    "| Harmonics all zero | Kn file still contains zeros | Replace the Kn files and re-run |\n",
    "| b3 is NaN/Inf | Kn value for n=3 is zero | Check row 3 of the Kn file (non-zero AbsRe/Im and CmpRe/Im) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}